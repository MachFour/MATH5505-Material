\documentclass[a4paper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyhdr}
\usepackage{framed}
\usepackage{hyperref}
\usepackage{pstricks,pst-node,pst-plot}
%\usepackage[english]{babel}
%\usepackage{enumerate }
%\usepackage{mathrsfs}
%\usepackage{graphicx}

\newrgbcolor{white}{1 1 1}
\newrgbcolor{nearlywhite}{0.95 0.95 0.95}
\newrgbcolor{offwhite}{0.9 0.9 0.9}
\newrgbcolor{lightgray}{0.85 0.85 0.85}
\newrgbcolor{halfgray}{0.8 0.8 0.8}
\newrgbcolor{halfdarkgray}{0.4 0.4 0.4}

\expandafter\let\expandafter\oldproof\csname\string\proof\endcsname
\let\oldendproof\endproof
\renewenvironment{proof}[1][\proofname]{%
  \oldproof[\scshape \noindent {\bfseries \text{Proof}}]%
}{\oldendproof}

\newenvironment{myitemize}
{\vspace*{-1mm}
 \begin{itemize}
    \setlength{\itemsep}{1pt}
    \setlength{\parskip}{1pt}
    \setlength{\parsep}{0pt}}
{\end{itemize}
 \vspace*{-1mm}}

\setlength{\topmargin}{0mm}
\addtolength{\oddsidemargin}{-.8\oddsidemargin}
\addtolength{\evensidemargin}{-.8\evensidemargin}
\addtolength{\textwidth}{+.3\textwidth}
\addtolength{\textheight}{+.05\textheight}
\setlength{\itemsep}{25mm}

\newcommand{\algorithm} {\bigskip\noindent{\bf Algorithm.}\;\;}
\newcommand{\example} {\bigskip\noindent{\bf Example.}\;\;}
\newcommand{\exercise}{\bigskip\noindent{\bf Exercise.}\;\;}
\newcommand{\lemma}{\bigskip\noindent{\bf Lemma.}\;\;}
\newcommand{\proposition}{\bigskip\noindent{\bf Proposition.}\;\;}
\newcommand{\remark}{\bigskip\noindent{\bf Remark.}\;\;}
\newcommand{\definition}{\bigskip\noindent{\bf Definition.}\;\;}
\newcommand{\challenge}{\bigskip\noindent{\bf Challenge.}\;\;}
\newcommand{\corollary}{\bigskip\noindent{\bf Corollary.}\;\;}
\newcommand{\notation}{\bigskip\noindent{\bf Notation.}\;\;}

\newenvironment{thm}[1]{
	\begin{framed}
	\noindent
	{\bfseries #1}\\}{\setlength{\itemsep}{0pt}
	\end{framed}
}

\newcommand{\ph}{\phantom}
\newcommand{\Af}{\mathcal{A}}
\newcommand{\Bf}{\mathcal{B}}
\newcommand{\Cf}{\mathcal{C}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\FF}{\mathbb{F}}
\newcommand{\Ff}{\mathcal{F}}
\newcommand{\If}{\mathcal{I}}
%\newcommand{\mathbb{N}}{\mathbb{N}}
\newcommand{\Pf}{\mathcal{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\Xf}{\mathcal{X}}
\newcommand{\Yf}{\mathcal{Y}}
\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\mybullet}{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillcolor=black,linecolor=black,framearc=.3,shadow=true}
  \pspicture(-.3,0)(.8,.4)\qdisk(.25,.2){.1}\pscircle*[linecolor=gray](.25,.2){.07}\endpspicture}

\newcommand{\nodea}{\nput[labelsep=0]{0}{a}{\mydot}}
\newcommand{\nodeb}{\nput[labelsep=0]{0}{b}{\mydot}}
\newcommand{\nodec}{\nput[labelsep=0]{0}{c}{\mydot}}
\newcommand{\noded}{\nput[labelsep=0]{0}{d}{\mydot}}
\newcommand{\nodee}{\nput[labelsep=0]{0}{e}{\mydot}}
\newcommand{\nodef}{\nput[labelsep=0]{0}{f}{\mydot}}
\newcommand{\nodeg}{\nput[labelsep=0]{0}{g}{\mydot}}
\newcommand{\nodeh}{\nput[labelsep=0]{0}{h}{\mydot}}
\newcommand{\nodei}{\nput[labelsep=0]{0}{i}{\mydot}}
\newcommand{\nodej}{\nput[labelsep=0]{0}{j}{\mydot}}

\newcommand{\edgeab}{\ncline{-}{a}{b}\Aput[.1 ]{5}\nodea\nodeb}
\newcommand{\edgeae}{\ncline{-}{a}{e}\Bput[.1 ]{3}\nodea\nodee}
\newcommand{\edgebc}{\ncline{-}{b}{c}\Aput[.1 ]{4}\nodeb\nodec}
\newcommand{\edgebe}{\ncline{-}{b}{e}\Aput[.08]{3}\nodeb\nodee}
\newcommand{\edgebi}{\ncline{-}{b}{i}\Bput[.1 ]{2}\nodeb\nodei}
\newcommand{\edgecd}{\ncline{-}{c}{d}\Aput[.1 ]{2}\nodec\noded}
\newcommand{\edgecf}{\ncline{-}{c}{f}\Bput[.06]{8}\nodec\nodef}
\newcommand{\edgecg}{\ncline{-}{c}{g}\Aput[.06]{3}\nodec\nodeg}
\newcommand{\edgedj}{\ncline{-}{d}{j}\Aput[.1 ]{1}\noded\nodej}
\newcommand{\edgeeh}{\ncline{-}{e}{h}\Bput[.1 ]{4}\nodee\nodeh}
\newcommand{\edgeei}{\ncline{-}{e}{i}\Aput[.08]{1}\nodee\nodei}
\newcommand{\edgefg}{\ncline{-}{f}{g}\Bput[.09]{2}\nodef\nodeg}
\newcommand{\edgefi}{\ncline{-}{f}{i}\Aput[.06]{3}\nodef\nodei}
\newcommand{\edgegj}{\ncline{-}{g}{j}\Bput[.06]{2}\nodeg\nodej}
\newcommand{\edgehi}{\ncline{-}{h}{i}\Bput[.1 ]{6}\nodeh\nodei}
\newcommand{\edgeij}{\ncline{-}{i}{j}\Bput[.1 ]{4}\nodei\nodej}

\newcommand{\mypicture}[1]{\pspicture(0,0)(0,0)\psset{unit=1cm,
 shadowcolor=offwhite,shadow=true,shadowangle=-45,linewidth=.03,linecolor=gray,
 fillcolor=lightgray,shadowsize=.15,framearc=.3}#1\endpspicture}

\newcommand{\myi}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny1}\endpspicture}}
\newcommand{\myii}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny2}\endpspicture}}
\newcommand{\myiii}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny3}\endpspicture}}
\newcommand{\myiv}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny4}\endpspicture}}
\newcommand{\myv}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny5}\endpspicture}}
\newcommand{\myvi}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny6}\endpspicture}}
\newcommand{\myvii}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny7}\endpspicture}}
\newcommand{\myviii}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny8}\endpspicture}}

\newcommand{\mymatrix}[1]{\psset{unit=4mm,linewidth=.03,linecolor=gray,fillstyle=solid,fillcolor=offwhite,shadow=false,framearc=0}\pspicture(0,0)(6,4)
  \psframe(0,0)(7,5)#1\psframe[linecolor=gray,fillcolor=offwhite,linewidth=.03,fillstyle=none,framearc=0](0,0)(7,5)\endpspicture}

\newcommand{\ds}{\displaystyle}
\newcommand{\mydot}{\pscircle(0,0){.1}}

\pagestyle{fancyplain}

\title{\Large\sc Chapter 2: Matching Theory}
\author{Thomas Britz}
\date{}

\begin{document}

\maketitle
\lhead{MATH5505}
\rhead{Combinatorics}


\section*{Hall's Marriage Theorem}

\begin{thm}{The Marriage Theorem}
  In a little traditional village,
  some girls are to be married monogamously to some boys.\\
  How many of the girls can get married?
  A set of girls can get married a boy if and only if
  each $k$-subset of these girls together like at least $k$ boys.
\end{thm}

\definition
Let $\Af = \{A_i\}_{i \in I}$ be a finite family of sets.\\
A \emph{matching} of $\Af$ is a set of distinct elements $\{a_i\}_{i \in I}$
with $a_i \in A_i$ for all $i \in I$.

\notation
Set $\Af (J) = \ds\bigcup_{i \in J} A_i$ for all $J \subseteq I$.

\example
Let $\Af = \{A_1, A_2\}$, where $A_1 = \{1,2\}$ and $A_2 = \{2,4\}$.\\
Then $\Af (\{1\}) = A_1 = \{1,2\}$ and $\Af(\{1,2\}) = \{1,2,4\}$.

\bigskip

This notation allows us to rewrite the Marriage Theorem (also called {\em Hall's Theorem}) as follows.

\begin{thm}{Theorem (Frobenius 1917, Hall 1935)}
$\Af$ has a matching if and only if $|\Af(J)| \geq |J|$ for all $J \subseteq I$.
\end{thm}

\begin{proof}
If $|\Af (J)| < |J|$ for some $J \subseteq I$, then $\Af$ has no matching.\\
Suppose therefore that $|\Af (J)| \geq |J|$ for all $J \subseteq I$.

If $|A_{i_0}| \geq 2$ for some $i_0 \in I$,
then let $x$ and $y$ be distinct elements of $A_{i_0}$.\\
Assume that we cannot remove $x$ or $y$ from $A_{i_0}$ without violating
the inequality in the theorem.\\
Then there are subsets $I_x$, $I_y \subseteq I - i_0$ so that
\begin{align*}
	|\Af(I_x) \cup (A_{i_0} - \{x\})| & \leq |I_x|\; \text{ and }\\
	|\Af(I_y) \cup (A_{i_0} - \{y\})| & \leq |I_y|\,.
\end{align*}

Thus,
\begin{align*}
	       |I_x| + |I_y|
    & \geq |\Af(I_x) \cup (A_{i_0} - \{x\})| + |\Af(I_y) \cup (A_{i_0} - \{y\})|\\
	& \geq | \Af(I_x) \cup (A_{i_0} - x) \cup \Af(I_y) \cup (A_{i_0} - y)| + |\Af(I_x) \cap \Af(I_y)|\\
	& \geq |\Af(I_x \cup I_y \cup \{i_0\})| + |\Af (I_x \cap I_y)|\\
	& \geq |I_x \cup I_y| + 1 + |I_x \cap I_y|\\
	& = |I_x| + |I_y| + 1\,,
\end{align*}
which is a contradiction.

We can therefore remove elements from the sets $A_i$ while preserving
the inequality in the theorem until $A_i = \{a_i\}$ for some $a_i$ for each $i \in I$.
Then $|\{a_i\}_{i \in I}| = |\Af(I)| \geq |I|$.
Hence, the elements $a_i$ are distinct, so $\{a_i\}_{i \in I}$ is a matching of $\Af$.
\end{proof}

\definition
A \emph{partial matching} of $\Af$ is a matching of some subfamily $\Bf \subseteq \Af$.

\example
$\Af = \{\{1\}, \{2\}, \{1,2\}\}$ has no matching.\\
However, $\Af$ does has the following partial matchings:
\[ \emptyset, \{1\}, \{2\}, \{1,2\}\,.\]
	
\begin{thm}{Theorem (Ore 1955)}
  $\Af$ has a partial matching of size $k$ if and only if,
  for all $J \subseteq I$, $|\Af (J)| \geq |J| - |I| + k$.
\end{thm}

\begin{proof}
Let $D$ be a set of $|I| - k$ ``dummy" elements not in $\Af(I)$.
Set $\Bf = \{A_i \cup D\}_{i \in I}$.\\
Then $\Af$ has a partial matching of size $k$ if and only if $\Bf$ has a matching.
For each $J \subseteq I$,
\[
   |\Bf (J)|
    = \Bigl| \bigcup_{i \in J} A_i \cup D\Bigr|\\
    = |\Af(J)| + |D|\\
    = |\Af(J)| + |I| - k\,.
\]
By the Marriage Theorem, $\Bf$ has a matching if and only if
$|\Bf(J)| \geq |J|$ for all $J \subseteq I$.\\
In other words, $\Af$ has a partial matching of size $k$
if and only if $|\Af(J)| \geq |J| - |I| + k$ for all $J \subseteq I$.
\end{proof}

\begin{thm}{Theorem (Ore 1955)}
A set $B$ contains a partial matching of $\Af$ of size $k$
if and only if, for all $J \subseteq I$,
\[
  |\Af(J) \cap B| \geq |J| - |I| + k\,.
\]
\end{thm}

\begin{proof}
Define $\Bf = \{A_i \cap B\}_{i \in I}$.\\
Then $B$ contains a partial matching of $\Af$ of size $k$
if and only if $\Bf$ has a partial matching of size $k$.\\
By the previous theorem, this is true precisely when
$|\Af(J) \cap B| = |\Bf(J)| \geq |J| - |I| + k$ for all $J \subseteq I$.
\end{proof}

\begin{thm}{Theorem (Ore 1955)}
A set $B$ is a partial matching of $\Af$ if and only if
for all $J \subseteq I$, $|\Af(J) \cap B| \geq |J| - |I| + |B|$.
\end{thm}

\begin{proof}
Set $k = |B|$ in Theorem 2.1.8.
\end{proof}

\begin{thm}{Theorem}
  A set $B$ is a partial matching of $\Af$ if and only if, for all $A \subseteq B$,
  $|\{i \in I : A_i \cap A \neq \emptyset\}| \geq |A|$.
\end{thm}

\begin{proof}
Define $\Cf = \{C_a\}_B$, where $C_a = \{i \in I : a \in A_i\}$.
Now, $B$ is a partial matching of $\Af$ if and only if $\Cf$ has a matching.
By Hall's Theorem, this is true precisely when $|\Cf(A)| \geq |A|$ for all $A \subseteq B$.\\
But $|\Cf(A)| = |\{i \in I : A_i \cap A \neq \emptyset\}|$, which concludes the proof.
\end{proof}

Let $\Af = \{A_i\}_{i \in I}$ be a finite family of subsets of a finite set $E$.
Consider the family $\If (\Af)$ of partial matchings of $\Af$.

\example
Let $\Af = \{\{1\}, \{2,3\}\}$.
Then
\[ \If(\Af) = \{ \emptyset, \{1\}, \{2\}, \{3\}, \{1,2\}, \{1,3\}\}\,.\]

\lemma
If $A \in \If(\Af)$ and $B \subseteq A$, then $B \in \If(\Af)$.

\definition
Let $\{z_{ai} : a \in E, i \in I\}$ be independent variables.\\
Define the \emph{formal incidence matrix} $M_\Af = (m_{ai})$ as follows:
\[ m_{ai} : = \begin{cases}
		z_{ai} & \text{ if } a \in A_i\\
		0 & \text{ if } a \not\in A_i\,.
	\end{cases}\]

\lemma
$B \in \If(\Af)$ if and only if the rows of $M_\Af$ indexed by $B$ are linearly independent.

\begin{proof}
The rows of $M_\Af$ indexed by $B$ are linearly independent\\
if and only if they contain a non-singular square submatrix $N$ of order $|B|$.

Such $N$ is non-singular precisely when
$\det N = \ldots + \prod_{a \in B} z_{ai_a} + \ldots \neq 0$.\\
This happens exactly when there is at least one nonzero term $\prod_{a \in B} z_{a i_a}$
(since the $z_{ai_a}$ are independent variables and cannot cancel each other).
This term corresponds to a partial matching~$B$.
\end{proof}


\begin{thm}{Theorem}\label{I-axioms}%
The family $\If(\Af)$ satisfies the following properties:
\begin{myitemize}
  \item[{(I1)}] $\emptyset \in \If(\Af)$.
  \item[{(I2)}] If $A \in \If(\Af)$ and $B \subseteq A$, then $B \in \If(\Af)$.
  \item[{(I3)}] If $A,B \in \If(\Af)$ and $|A| < |B|$,
               then $A \cup \{a\} \in \If(\Af)$ for some $a \in B-A$.
\end{myitemize}
\end{thm}

\begin{proof}
These properties are true for any finite family of finite sets of linearly independent vectors in some vector space.
The proof therefore follows from the preceding lemma.
\end{proof}

Since $(E, \If(\Af))$ satisfies the properties (I1-3),
it is a \emph{matroid} (or \emph{independence structure} or \emph{combinatorial geometry}).
In particular, it is a {\em transversal matroid}.
Matroids arise in numerous ways and are very useful in combinatorics.
We shall meet them again at the end of this chapter.

%\example
%Let $E$ be a finite set and let $\If$ be the subsets of $E$ of size at most $k$.\\
%Then $(E, \If)$ is a matroid.

\corollary
The maximal partial matchings of $\Af$ have equal size.

\begin{proof}
This follows by the third matroid property (I3).
\end{proof}

{\bigskip\noindent{\bf Corollary (Hoffman and Kuhn 1956)}\\
A set $M$ is contained in a matching of $\Af$ if and only if\\
$\Af$ has a matching and $M$ is a partial matching of~$\Af$.

\begin{proof}
This also follows from the third matroid property (I3).
\end{proof}


\newpage
\section*{K\"onig's Theorem}

\definition
Let $A$ be a $(0,1)$-matrix.
A \emph{line} is a row or a column.\\
A \emph{partial transversal} is a set of 1-entries with no common line.

\begin{thm}{K\"onig's Theorem (1916)}
The maximal size $M$ of partial transversal in $A$ equals\\
the minimal number $m$ of lines needed to cover all 1-entires of $A$.
\end{thm}

\begin{proof}
Note that $M \leq m$.
We therefore only need to prove that $M \geq m$.\\
Let the 1s be covered by rows $R$ and columns $C$ where $|R| + |C| = m$.\\
Define $\Af_R = \{C_i\}_R$, where $C_i = \{ j \not\in C : a_{ij} = 1\}$,
and let $J \subseteq R$.
Then $|\Af_R (J)| \geq |J|$.\\
Otherwise, we could replace the rows $R$ by fewer columns,
contradicting the minimality of $m$.

By Hall's Theorem, $\Af_R$ has a matching,
corresponding to a partial transversal $T_R$ of size $|R|$,
that lies in rows $R$ outside of columns $C$.
Similarly, there is a partial transversal $T_C$ of size $|C|$
that lies in columns $C$ outside of rows $R$.

Then $T_R \cup T_C$ is a partial transversal of size $|R| + |C| = m$.
Hence, $M \geq m$.
\end{proof}


\begin{center}
\pspicture(0,-.5)(0,2.75)\psset{unit=1cm,
 shadowcolor=offwhite,shadow=true,shadowangle=-45,linewidth=.03,linecolor=gray,
 fillcolor=lightgray,shadowsize=.15,framearc=.3}
  \mymatrix{\psset{linecolor=gray,fillcolor=halfgray}
  \psframe(0,0)(2,5)\rput(-1,4){$R$}\psframe(0,3)(7,5)\rput(1,6){$C$}\psline(2,0)(2,5)
%  \psframe[fillcolor=gray](3,3)(4,4)\rput(3.5,3.5){1}
  \psframe[fillcolor=gray](3,4)(4,5)\rput(3.5,4.5){\white1}
  \psframe[fillcolor=gray](5,3)(6,4)\rput(5.5,3.5){\white1}
  \psframe[fillcolor=gray](0,0)(1,1)\rput( .5, .5){\white1}
  \psframe[fillcolor=gray](1,1)(2,2)\rput(1.5,1.5){\white1}}
\endpspicture
\end{center}

\begin{thm}{Theorem}
Hall's Theorem and K\"onig's Theorem are equivalent.
\end{thm}

\begin{proof}
We have shown already that Hall's Theorem implies K\"onig's Theorem.\\
We must then prove that Hall's Theorem follows from K\"onig's Theorem.\\
So, let $\Af = \{A_i\}_{i \in I}$ be
a finite family of subsets of a finite set $E$
so that $|\Af(J)| \geq |J|$ for all $J \subseteq I$.\\
We now need to show that $\Af$ has a matching.

Define $A = (m_{ia})$, where $m_{ia} = 1$ if $a \in A_i$ and $m_{ia} = 0$ otherwise.\\
Cover the 1s of $A$ with rows indexed by $R$ and columns indexed by $C$,
with $m = |R| +|C|$ minimal.\\
The 1s in rows $J = I-R$ lie in columns $C$.
Then $|C| \geq |\Af(J)| \geq |J| = |I| - |R|$,
so $m = |C| + |R| \geq |I|$.

By K\"onig's Theorem, $A$ has a partial transversal of size $m = |I|$.
That is, $\Af$ has a matching.
\end{proof}


\newpage
\section*{Dilworth's Theorem}

\definition
A \emph{partially ordered set} (or \emph{poset}) is a set $P$ with
a \emph{partial order} $\preceq$ so that, for all $x,y,z \in P$,

\begin{myitemize}
  \item[](R)eflexivity: $x \preceq x$.\vspace*{-.5mm}
  \item[](A)nti-symmetry: If $x \preceq y$ and $y \preceq x$, then $x = y$.\vspace*{-.5mm}
  \item[](T)ransitivity: If $x \preceq y$ and $y \preceq z$, then $x \preceq z$.
\end{myitemize}

\definition
Two elements $x,y\in P$ are {\em comparable} if either $x\preceq y$ or $y\preceq x$.\\
A {\em chain} is a subset of elements of $P$ whose elements are all pairwise comparable.\\
An {\em antichain} is a subset of elements of $P$ no two elements of which are comparable.

\example

\begin{center}
{\psset{unit=1cm,
 shadowcolor=offwhite,shadow=true,shadowangle=-45,linewidth=.03,linecolor=gray,
 fillcolor=lightgray,shadowsize=.15,framearc=.3}
 \psset{unit=10mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,fillstyle=solid,
  linecolor=gray,shadowcolor=offwhite,shadow=true,shadowsize=.125,shadowangle=-45,dash=7pt 5pt}
  \pspicture(0,-.5)(8,2.75)
  \pscircle(1,3){.09}\psline(1,2.13)(1,2.87)\pscircle(1,2){.09}
  \pscircle(0,1){.09}\psline(.09,1.09)(.91,1.91)\psline(1,1.13)(1,1.87)
  \pscircle(1,1){.09}\psline(1,.13)(1,.87)\pscircle(1,0){.09}
  \pscircle(2,2){.09}\psline(1.09,1.09)(1.91,1.91)
  \rput(-.28,1){3}\rput(.72,0){2}
  \rput(.67,1){10}\rput(1.33,2){30}\rput(1.33,3){60}\rput(2.33,2){40}
  \endpspicture}
\end{center}
The set $\{2,3,10,30,40,60\}$ with $x \preceq y$ defined by $x | y$ is a poset $P$.\\
Elements $2$ and $10$ are comparable since $2|10$ and thus $2\preceq 10$.\\
In contrast, $2\npreceq 3$ and $3\npreceq 2$, so $2$ and $3$ are not comparable.\\
The subset $\{2,10,30,60\}$ is a chain in $P$ and $\{3,10\}$ is an antichain in $P$.

\begin{thm}{Dilworth's Theorem (1950)}
The minimal number $m$ of disjoint chains covering a finite poset $P$ equals\\
the maximal size $M$ of an antichain.
\end{thm}

\begin{proof}
Note that $m \geq M$.
We therefore only need to prove that $m \leq M$.\\
Assume that the theorem holds for all posets on fewer than $|P|$ elements.\\
Choose a maximal chain $C$ in $P$.

If every antichain in $P-C$ has at most $M-1$ elements,
then by the induction assumption,\\
$P-C$ can be covered by $M-1$ disjoint chains.
Together with $C$, these chains cover $P$.
Hence, $m \leq M$.

Suppose that $A$ is an antichain in $P-C$ with $M$ elements.
Set
\begin{align*}
	A^- & = \{x \in P : x \preceq a \text{ for some } a \in A\}\\
	A^+ & = \{x \in P : a \preceq x \text{ for some } a \in A\}\,.
\end{align*}
Since $|A| = M$, $P = A^- \cup A^+$.
By the maximality of $C$,
element $\max(C)$ is not in~$A^-$.
Hence, $|A^-| < |P|$.
By the induction assumption, $A^-$ is
a union of $M$ disjoint chains~$C_a^-$ with $\max(C_a^-) = a \in A$.

Similarly, $A^+$ is a union of $M$ disjoint chains $C_a^+$ with $\min(C_a^+) = a \in A$.\\
Then $P$ is the union of the $M$ disjoint chains $C_a^- \cup C_a^+$.
Hence $m \leq M$.
\end{proof}

\newpage
\begin{thm}{The Dual of Dilworth's Theorem (Mirsky 1971)}
The minimal number $m$ of disjoint antichains covering the poset $P$ equals\\
the maximal size $M$ of a chain.
\end{thm}

\begin{proof}
Note that $m \geq M$.
We therefore only need to prove that $m \leq M$.\\
For each $i=1,\dots,M$, define
\[ A_i = \{ x \in P : i = \text{ the longest length of a chain starting in } x\}\,.\]
Then $A_1, \cdots, A_M$ are nonempty disjoint antichains that together cover $P$.
Hence $m \leq M$.
\end{proof}

Note that Dilworth's Theorem is harder to prove than its dual!\\
This means that chains and antichains are not completely interchangeable.

\begin{thm}{Theorem}
Hall's Theorem, K\"onig's Theorem, and Dilworth's Theorem are equivalent.
\end{thm}

\begin{proof}
We have previously shown the equivalence of Hall's and K\"onig's Theorems.
We must now prove that Dilworth's Theorem is equivalent to these.

Let us begin by showing that Dilworth's Theorem implies Hall's Theorem.\\
Let $\Af = \{A_i\}_{i\in I}$ be
a finite family of subsets of a finite set $E$
so that $|\Af(J)| \geq |J|$ for all $J \subseteq I$.
We must show that $\Af$ has a matching.
Define the poset $P = E \cup \Af$ with partial order $\preceq$ given by $a \prec A$
if and only if $a \in A$ ($a \in E, A \in \Af)$.
Thus the chains in $P$ have length 1 or 2.

Let $F \cup \{A_j\}_{j \in J}$ be an antichain of maximal size in $P$ where $F \subseteq E$.
By Dilworth's Theorem, $P$~can be covered by $|F| + |J|$ disjoint chains
and each of these must cover an element of $F \cup \{A_j\}_{j \in J}$.
In~particular, $|J|$ of these chains cover $\{A_j\}_{j \in J}$
and must also cover the elements $\Af(J)$.
Since $|\Af(J)| \geq |J|$, we have equality,
and these $|J|$ chains correspond to
a matching $B_1 = \{a_j\}_{j \in J}$ of $\{A_j\}_{j \in J}$.

Similarly, $\{A_j\}_{j \in I-J}$ must be covered by chains $(a, A_j)$ where $a \in F$.
This corresponds to a matching $B_1 = \{a_j\}_{j \in I-J}$ of $\{A_j\}_{j \in I-J}$.
Thus, $B_1 \cup B_2$ is a matching for $\Af = \{A_i\}_{i \in I}$.

We now show that K\"onig's Theorem implies Dilworth's Theorem.
Suppose that $P$ is a finite poset and let $M = (m_{ab})$ be
the matrix with $m_{ab} = 1$ if $a \prec b$ and $m_{ab} = 0$ otherwise.

Now, if $a \prec b \prec c \prec \cdots \prec y \prec z$ is a chain of length $n$ in $P$,
then the entries $m_{ab}, m_{bc}, \ldots, m_{yz}$ form
a partial transversal of size $n-1$ in $M$.
Thus, a covering of $P$ by $j$ chains corresponds in $M$ to
a partial transversal of size $|P|-j$.
Conversely, a partial transversal of size $|P| - j$
corresponds to $j$ chains that cover $P$.

Now, consider $m$ chains that cover $P$, where $m$ is minimal.
This corresponds to a partial transversal in $M$ of maximal size $|P|-m$.
By K\"onig's Theorem, the 1-entries of $M$ can be covered by $|P|-m$ lines,
indexed by at most $|P|-m$ elements of $P$.
There are thus at least $m$ elements no indexed;
these form an antichain in $P$.
\end{proof}


\newpage
\section*{Applications}

\definition
Let $M := (m_{ij})$ be a real $n \times n$ matrix.\\
A \emph{transversal} of $M$ is $n$ nonzero entries with no common line.\\
A \emph{permutation matrix} is a square $(0,1)$-matrix with one 1-entry in each line.

\begin{thm}{The Birkhoff-Neumann Theorem (1946, 1953)}
The line sums of $M$ all equal $t$ if and only if, for permutation matrices $P_i$,
\[ M = \sum_{i=1}^m c_i P_i\,,\qquad \text{where}\qquad \sum_{i=1}^m c_i = t\,.\]
\end{thm}

\begin{proof}
If $M = \sum_i c_i P_i$ with $\sum_i c_i = t$,
then all the line sums of $M$ equal $t$.
Therefore, suppose that each line sum of $M$ equals $t$.

If $M$ has negative entries, then let $a = \min m_{ij}$
and let $M' = M + |a| J_n$, where $J_n$ is all-1 $n \times n$ matrix.
Then each entry of $M'$ is nonnegative and each line sum equals $t = |a| n$.
Since $|a|J_n$ is a weighted sum of permutation matrices,
we can assume without loss of generality, that $M$ is nonnegative.

If $t = 0$, then $M = 0 \times P$ for any permutation matrix $P$, so assume $t > 0$.

Thus, suppose that $M \geq 0$ and each line sum equals $t > 0$.

We use induction on the number of nonzero entries in $M$.\\
Define $\Af = \{A_i\}_{i \in I}$,
where $A_i = \{j : m_{ij} > 0\}$ and $I = \{1, \ldots, n\}$.
Consider any subset $J \subseteq I$.
Then
\[
       |\Af(J)|t
    =  \sum_{j \in \Af(J)} \sum_{i \in I} m_{ij}\\
  \geq \sum_{j \in \Af(J)} \sum_{i \in J} m_{ij}\\
  \geq \sum_{i \in J} \sum_{j \in A_i} m_{ij}\\
	=  \sum_{i \in J} t\\
	=  |J| t\,.
\]
Hence, $|\Af(J)| \geq |J|$.
By Hall's Theorem, $\Af$ has a matching,
corresponding to a transversal $T$ of $M$
and represented by a permutation matrix $P$.
Let $c > 0$ be the minimal value of the entries $T$.
Then $M' = M -cP$ has all line sums equal to $t - c \geq 0$,
and $M'$ has fewer nonzero entries than $M$.

By induction, $M' = \sum_i c_i P_i$ for permutation matrices $P_i$
and $\sum_i c_i = t-c$.
Adding $P$ to $M'$ gives $M = cP + \sum_i c_i P_i$.
\end{proof}

\example
We have the following decompostion, where $t = 4$:
	\[ \begin{pmatrix}
		-1 & 4 & 1 \\ 3 & 1 & 0 \\ 2 & -1 & 3
	\end{pmatrix} = -\begin{pmatrix}
		1 & 0 & 0 \\ 0 & 0 & 1 \\ 0 & 1 & 0
	\end{pmatrix} + \begin{pmatrix}
		0 & 0 & 1\\ 0 & 1 & 0 \\ 1 & 0 & 0
	\end{pmatrix} + 3 \begin{pmatrix}
		0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1
	\end{pmatrix} + \begin{pmatrix}
		0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0
	\end{pmatrix}\,.\]

\corollary
$M$ is doubly stochastic (i.e. all line sums  equal 1)
if and only if\\
$M = \sum_i c_i P_i$ for permutation matrices $P_i$ and $\sum_i c_i = 1$.

\begin{thm}{(K\"onig 1916)}
If $M$ is a nonnegative matrix with integer entries and constant line sums,\\
then $M = \sum_i P_i$ for permutation matrices $P_i$.
\end{thm}

\newpage
\definition
A \emph{Latin rectangle} is a matrix in which no line has repeated entries.\\
A \emph{Latin square} is a square Latin rectangle.\\
A Latin rectangle is \emph{incomplete} if it has some empty entries.\\
We will assume that each $n\times n$ Latin square contains $n$ types of symbols, or fewer if incomplete.

\example\vspace*{-2mm}
\[
  M = \begin{pmatrix}
	    1 & 3 & 4 & 2\\
        3 & 1 & 2 & 4\\
        4 & 2 & 1 & 3
      \end{pmatrix} \qquad
  N = \begin{pmatrix}
		1 & 3 & 4 & 2\\
        3 & 1 &   &  \\
        4 &   & 1 & 3\\
        2 & 4 & 3
      \end{pmatrix}
\]
The above matrix $M$ is a Latin rectangle,
and $N$ is an incomplete Latin square.


\begin{thm}{Theorem (Ryser 1956)}
Each $r \times n$ Latin square ($r < n$) can be extended to an $n \times n$ Latin square.
\end{thm}

\begin{proof}
By induction, we need only show that one row can be added.
Let $A_i$ be the set of elements not in
the $i^{th}$ column of the rectangle $R$,
and set $\Af = \{A_i\}_{i \in I}$ where $I = \{1,\ldots, n\}$.
Now that $|A_i| = n-r$.

Consider any subset $J \subseteq I$.
Each element appears $r$  times in $R$ and therefore $n-r$ times in the sets~$A_i$.
Therefore, each element can appear at most $n-r$ times in
the sets $A_i$, where $i \in J$.
Then
\[
    |J| (n-r)
  = \sum_{i \in J} |A_i|
  = \sum_{j \in \Af(J)} |\{ i \in J : j \in A_i\}|
  \leq |\Af(J)| (n-r)\,.
\]
Hence, $|\Af(J)| \geq |J|$.
By Hall's Theorem, $\Af$ has a matching, which gives a new row for $R$.
\end{proof}

Hall's Theorem can also be used to prove stronger results like the following two celebrated theorems.

\begin{thm}{Ryser's Theorem (1956)}
An $r \times s$ Latin rectangle on $n$ symbols can be extended to
an $n \times n$ Latin square if and only if\\
each symbol occurs at least $r+s-n$ times.
\end{thm}

\begin{thm}{Evan's Conjecture (Smetianuk 1981)}
An incomplete Latin $n \times n$ square with at most $n-1$ entries
can be completed to a Latin square of order $n$.
\end{thm}

\definition
The \emph{Boolean lattice} $\Bf_n$ is
the poset of subsets of $\{1,\ldots, n\}$ under inclusion.

\begin{thm}{Algorithm}
A \emph{symmetric chain decomposition} of $\Bf_n$ is given inductively as follows:
\begin{myitemize}
  \item[\myi]   The chain $\emptyset \subset \{1\}$ decomposes $\Bf_1$ (trivially).
  \item[\myii]  Suppose that $\Cf$ decomposes $\Bf_n$ into disjoint symmetric chains.
  \item[\myiii] Replace each chain $P_k \subset P_{k+1} \subset \dots \subset P_{n-k}$ in $\Cf$
        with $|P_i| = i$ by
  \[
    P_{k+1} \subset \dots \subset P_{n-k}\qquad\text{and}\qquad
    P_k     \subset P_k \cup \{n+1\} \subset \dots \subset P_{n-k} \cup \{n+1\}\,.
  \]
\end{myitemize}
\end{thm}

\example\\
$\Bf_2$ decomposes into $\{1\}$ and $\emptyset \subset \{2\} \subset \{1,2\}$.\\
$\Bf_3$ decomposes into $\emptyset \subset \{3\} \subset \{2,3\} \subset \{1,2,3\}$,
$\{1\} \subset \{1,3\}$,
and $\{2\} \subset \{1,2\}$.


\begin{thm}{Sperner's Theorem (1928)}
  If $\Af$ is a family of subsets of $\{1,\ldots, n\}$
  with $A \not\subset B$ for all $A,B \in \Af$,
  then $|\Af| \leq \binom{n}{\lfloor/2\rfloor}$.
\end{thm}

\begin{proof}
The family $\Af$ is an antichain in $\Bf_n$.
By the trivial direction of Dilworth's Theorem,
$|\Af| \leq m$, where $m$ is the minimal number of chains to cover $\Bf_n$.
The symmetric chain decomposition algorithm gives
a covering of $\Bf_n$ by disjoint chains that
each contain one member of $P$ of size $|P| = \lfloor n/2\rfloor$.
There are $\binom{n}{\lfloor n/2\rfloor}$ such members.
Hence, $|\Af| \leq m \leq \binom{n}{\lfloor n/2\rfloor}$.
\end{proof}

\begin{thm}{The Erd\"os-Szemeredi Theorem (1935)}
Each sequence $a_1, \ldots, a_{n^2 +1}$ of $n^2+1$ distinct integers has
a subsequence with $n+1$ elements that is either increasing or decreasing.
\end{thm}

\begin{proof}
Define a poset $P$ on the elements $a_1, \ldots, a_{n^2+1}$,
where $a_i \preceq a_j$ if and only if $i \leq j$ and $a_i \leq a_j$.
The chains in $P$ correspond to the decreasing subsequences.

If there is an increasing subsequence of size $n+1$, then we are done.
Suppose then that all increasing subsequences have length at most $n$.
In other words, the chains of $P$ have length at most $n$.

By the Dual of Dilworth's Theorem,
we can cover $P$ by at most $n$ antichains.\\
Since $|P| > n^2$, at least one antichain must have at least $n+1$ elements.\\
Thus, there is a decreasing subsequence of size at least $n+1$.
\end{proof}

\example
Consider the following sequence of $n^2 + 1$ integers where $n=3$:
	\[ 7 \; 8 \; 9 \; 4 \; 5 \; 6 \; 1 \; 2 \; 3 \; 0\,.\]
There is no increasing subsequence of size $n+1=4$.\\
However, there is a decreasing subsequence of size $n+1=4$.


\section*{Generalisations}

{\bfseries Recall} that $(E,\If)$ where $\If\subseteq \mathcal{P}(E)$ is a \emph{matroid} if and only if

\begin{myitemize}
  \item[{(I1)}] $\emptyset \in \If$.
  \item[{(I2)}] If $A \in \If$ and $B \subseteq A$, then $B \in \If$.
  \item[{(I3)}] If $A,B \in \If$ and $|A| < |B|$,
              then $A \cup \{a\} \in \If$ for some $a \in B - A$.
\end{myitemize}

\definition
The \emph{rank function} $\rho$ of $M$ is defined by
	\[ \rho(A) = \max\{|B| : B \subseteq A, B \in \If\}\,.\]
A subset $A$ is \emph{independent} with respect to $M$ if $\rho(A) = |A|$.

\begin{thm}{Theorem} For all $A, B \subseteq E$,
	\[ \rho(A) + \rho(B) \geq \rho(A \cup B) + \rho(A \cap B)\,.\]
\end{thm}

\begin{proof}
Let $X \subseteq A \cap B$ be an independent subset with $|X| = \rho(A \cap B)$.
Then $X$ is in an independent subset $Y \subseteq A \cup B$ with $|Y| = \rho(A \cup B)$.
Set $Y_A = Y - B$ and $Y_B = Y-A$ and note that $Y = X \cup Y_A \cup Y_B$.
Then $X \cup Y_A$ is an independent subset of $A$.
Also, $X \cup Y_B$ is an independent subset of $B$.
Hence,
\[
       \rho(A) + \rho(B)
  \geq |X \cup Y_A| + |X \cup Y_B|
	= |X| + |Y|
	= \rho(A\cap B) + \rho(A \cup B)\,.\qedhere
\]
\end{proof}

\noindent
Let $\Af = \{A_i\}_{i \in I}$ be a finite family of subsets of a finite set $E$.\\
Also, let $(E,\mathcal{I})$ be a matroid,
and call each partial matching $M$ of $\Af$ {\em independent} if $M\in \mathcal{I}$.

\begin{thm}{Rado's Theorem (1942)}
  $\Af$ has an independent matching if and only if
  $\rho(\Af(J)) \geq |J|$ for all $J \subseteq I$.
\end{thm}

\begin{proof}
If $\rho(\Af(J)) < |J|$ for some $J \subseteq I$,
then there is no independent matching of $\{A_i\}_{i \in J}$
and thus no independent matching of $\Af$.
Suppose therefore that $\rho(\Af(J)) \geq |J|$ for all $J \subseteq I$.

If $\rho(A_j) \geq 2$ for some $j \in \If$,
then let $x$ and $y$ be distinct elements of $A_j$.\\
Assume that we cannot remove $x$ or $y$ from $A_j$
without violating the inequality in the theorem.\\
Then there are subsets $I_x, I_y \subseteq I - j$ so that
\begin{align*}
  \rho(\Af(I_x) \cup (A_j - \{x\})) & \leq |I_x|\\
  \rho(\Af(I_y) \cup (A_j - \{y\})) & \leq |I_y|\,.
\end{align*}
Thus,
\begin{align*}
        |I_x| + |I_y|
  &\geq \rho( \mathcal{A}(I_x)\cup (A_j - x))  + \rho(\mathcal{A}(I_y)\cup (A_j - y))\\
  &\geq \rho( \mathcal{A}(I_x)\cup (A_j - x)  \cup \mathcal{A}(I_y)\cup (A_j - y))
     +  \rho((\mathcal{A}(I_x)\cup (A_j - x)) \cap(\mathcal{A}(I_y)\cup (A_j - y)))\\
  &\geq \rho( \mathcal{A}(I_x)\cup (A_j - x)  \cup \mathcal{A}(I_y)\cup (A_j - y))
     +  \rho( \mathcal{A}(I_x)\cap \mathcal{A}(I_y))\\
  &\geq \rho( \mathcal{A}(I_x\cup I_y \cup \{j\}))
     +  \rho( \mathcal{A}(I_x\cap I_y))\\
  &\geq |I_x\cup I_y| + 1 +|I_x\cap I_y|\\
  & =   |I_x| + |I_y| + 1\,,
\end{align*}
a contradiction.
We can thus remove the elements from the sets $A_i$
while preserving the inequality in the theorem,
until $A_i = \{a_i\}$ for some $a_i$ for each $i \in I$.
Then $|\{a_i\}_{i\in I}| \geq \rho(\{a_i\}_{i \in I}) = \rho(\Af(I)) \geq |I|$.
Hence, the elements $a_i$ are distinct, so $\{a_i\}_{i \in I}$ is a matching if $\Af$.
\end{proof}

Let $\Af = \{A_i\}_{i \in I}$ and $\Bf = \{B_i\}_{i \in I}$
be families of finite sets indexed by $I$.

\begin{thm}{Ford and Fulkerson (1962)}
$\Af$ and $\Bf$ have a matching in common if and only if, for all $J_A, J_B \subseteq I$,
\[ |\Af(J_A) \cap \Bf(J_B)| \geq |J_A| + |J_B| - |I|\,.\]
\end{thm}

\begin{proof}
Let $\rho$ be the rank function of the matroid associated to $\If(\Af)$.
Then a set is a common matching of $\Af$ and $\Bf$ if and only if
it is an independent matching of $\Bf$.
By Rado's Theorem, such a set exists if and only if
$\rho(\Bf(J_B)) \geq |J_B|$ for all $J_B \subseteq I$.
That is, if and only if $\Bf(J_B)$ contains
a partial matching of $\Af$ of size $|J_B|$.
By Ore's theorems, this occurs precisely when, for all $J_A \subseteq I$,
	\[ \Af(J_A) \cap \Bf(J_B)| \geq |J_A| - |I| + |J_B|\,.\]
\end{proof}

%We are going to define representations of the chains,
%denoted by $\triangle$, and antichains, denoted by $\tilde{\triangle}$,
%in a given poset using the following example.

\example
Consider the poset given by the following graph:
\begin{center}
  \psset{unit=10mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,
  linecolor=gray,shadowcolor=offwhite,shadow=true,shadowsize=.125,shadowangle=-45}
  \pspicture(-0.2,-.5)(5,3.3)
    \rput[l](2.8,3   ){maximal size of 1 chain\ph{s}= 4}
    \rput[l](2.8,2.6 ){maximal size of 2 chains     = 6}
    \rput[l](2.8,1.2 ){maximal size of 1 antichain\ph{s} = 2}
    \rput[l](2.8,0.80){maximal size of 2 antichains = 4}
    \rput[l](2.8, .40){maximal size of 3 antichains = 5}
    \rput[l](2.8, .00){maximal size of 4 antichains = 6}
    \rput(9.5,2.9){\pspicture(0,0)(0,1)
      \psset{unit=4mm,linecolor=gray,fillcolor=halfgray,shadowsize=.2,framearc=.3}
      \rput(-1.5,1.065){$\text{\large$\Delta$}\:=$}
      \psframe(0.05,1.05)(0.95,1.95)\psframe(1.05,1.05)(1.95,1.95)
      \psframe(2.05,1.05)(2.95,1.95)\psframe(3.05,1.05)(3.95,1.95)
      \psframe(0.05,0.05)(0.95,0.95)\psframe(1.05,0.05)(1.95,0.95)
      \endpspicture}
    \rput(9.5,.3){\pspicture(0,0)(0,1)
      \psset{unit=4mm,linecolor=gray,fillcolor=halfgray,shadowsize=.2,framearc=.3}
      \rput(-1.5,2.165){$\text{\large$\tilde{\Delta}$}\,=$}
      \psframe(0.05,3.05)(0.95,3.95)\psframe(1.05,3.05)(1.95,3.95)
      \psframe(0.05,2.05)(0.95,2.95)\psframe(1.05,2.05)(1.95,2.95)
      \psframe(0.05,1.05)(0.95,1.95)
      \psframe(0.05,0.05)(0.95,0.95)
      \endpspicture}
 {\psset{unit=10mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,fillstyle=solid,
  linecolor=gray,shadowcolor=offwhite,shadow=true,shadowsize=.125,shadowangle=-45,dash=7pt 5pt}
  \pspicture(0,0)(7,3)
  \pscircle(1,3){.09}\psline(1,2.13)(1,2.87)\pscircle(1,2){.09}
  \pscircle(0,1){.09}\psline(.09,1.09)(.91,1.91)\psline(1,1.13)(1,1.87)
  \pscircle(1,1){.09}\psline(1,.13)(1,.87)\pscircle(1,0){.09}
  \pscircle(2,2){.09}\psline(1.09,1.09)(1.91,1.91)
  \endpspicture}
  \endpspicture
\end{center}


%We then have that
%\begin{align*}
%	\begin{array}{rcl}
%		\text{Maximal size of 1 chain} & = & 4,\\
%		\text{Maximal size of 2 chains} & = & 6,\\
%	\end{array} && \triangle = \begin{matrix}
%		\square & \square & \square & \square \\ \square & \square
%	\end{matrix}\\\\
%	\begin{array}{rcl}
%		\text{Maximal size of 1 antichain} & = & 2,\\
%		\text{Maximal size of 2 antichains} & = & 4,\\
%		\text{Maximal size of 3 antichains} & = & 5,\\
%		\text{Maximal size of 4 antichains} & = & 6
%	\end{array} && \tilde{\triangle} = \begin{matrix}
%		\square & \square \\ \square & \square \\ \square \\ \square
%	\end{matrix}
%\end{align*}

\begin{thm}{Greene's Duality Theorem (1976)}\vspace*{-3mm}
	\[ \triangle = \tilde{\triangle}^T\vspace*{-3mm}\]
\end{thm}

Note that Greene's Duality Theorem implies both Dilworth's Theorem and its dual.


\section*{Graph Algorithms}


%\section*{Introduction}

\vspace*{-6mm}
\definition
A \emph{graph} $G =(V,E)$ consists of \emph{vertices} $V$
and \emph{edges} $E \subseteq \binom{V}{2}$.\\
We can draw $G$ as dots (vertices) and lines between the dots (edges).\\
A graph is {\emph simple} if no edge is adjacent to just one vertex
and no two edges share the same endpoints.\\
A graph $G = (V,E)$ is \emph{bipartite} if there is a bipartition $V = X \cup Y$
so that all edges go from one part to the other, i.e.,
$E \cap \binom{X}{2} = E \cap \binom{Y}{2} = \emptyset$).

\smallskip
\noindent
A \emph{matching} is a set of disjoint edges.\\
Vertex set $X \subseteq V$ is \emph{matched} if it is covered by a matching.\\
A \emph{complete matching} (or \emph{1-factor}) is a matching that covers $V$.\\
The neighbours of vertices $Z \subseteq V$ are denoted by $N(Z)$.\\
That is, $N(Z) = \{u \in V : \{u,v\} \in E \text{ for some } v \in Z\}$.

\smallskip
\noindent
Let $\Af = \{A_i\}_{i \in I}$ be a finite family of sets.\\
Define $B = (V, E_B)$,
where $V = \Af \cup \Af(I)$ and $E_B = \{\{a,A\} : a \in A\}$.\\
Then $\Af$ has a matching if and only if $\Af$ is matched in $B$.\\
The Marriage Theorem has the following natural bipartite graph expression.\vspace*{-1.5mm}

\begin{thm}{The Marriage Theorem (Frobenius 1917, Hall 1935)}
Let $B = (X\cup Y, E_B)$ be a bipartite graph.\\
Then $X$ is matched in $B$ if and only if for all $A \subseteq X$, $|N(A) \geq |A|$.
\end{thm}

\vspace*{-5.5mm}
\definition
Let $G = (V,E)$ be a graph.\\
A \emph{walk} in $G$ is a sequence of vertices $v_1, \ldots, v_n$
with $\{v_i, v_{i+1}\} \in E$.\\
A \emph{path} in $G$ is a walk with no repeated vertex.\\
A \emph{closed walk} in $G$ is a walk of the form $v_1, \ldots, v_n, v_1$.\\
A \emph{cycle} in $G$ is a closed walk with no repeated vertex but the first and last.\\
If a walk exists between each pair of vertices in $G$,
then $G$ is \emph{connected}.\\
The  \emph{maximally connected subgraphs} of $G$ are components of $G$.\\
Let $c_0 (G)$ denote the number of components in $G$ of odd vertex size.\vspace*{-1mm}
\begin{thm}{(Tutte's 1-Factor Theorem 1947)}
$G$ has a complete matching if and only if for all $S \subseteq V$, $c_0 (G-S) \leq |S|$.
\end{thm}\vspace*{-5mm}

\newpage
\section*{Augmenting Paths}

\definition
Let $G = (V,E)$ be a (simple) graph and let $M$ be a matching in $G$.\\
An \emph{alternating path} for $M$ is a path where every second edge lies in $M$.\\
An alternating path $P$ is \emph{augmenting} if its end-edges lie outside $M$.\\
Let $E(P)$ denote the edges along $P$.

\lemma
The set of edges $M' = M \oplus E(P)$ is a matching of size $|M'| = |M| + 1$.

\begin{proof}
The vertices covered by $M'$ are those of $P$.\\
Each is in one edge of $M'$, so $M'$ is a matching, and $|M'| = |M|+1$.
\end{proof}

\begin{thm}{Theorem}
$M$ has maximal size in $G$ if and only if $M$ has no augmenting path.
\end{thm}

\begin{proof}
We have previously shown that $M$ is not maximal if an augmenting path exists.

Suppose that no such path exists and let $M'$ be a maximal matching in $G$.
Each vertex of $G = M \oplus M'$ is in at most one edge of $M$ and of $M'$.
Thus, $D$ is a disjoint union of cycles and alternating paths.

The edges alternate between $M$ and $M'$, so each cycle has even edge total.
By assumption, no path is augmenting, so each path has even edge totals.
Therefore, all of the cycles and paths contain the same number of edges
from $M$ as from $M'$.
This imples that $|M-M'|=|M'-M|$.
Hence,
\[|M| = |M-M'| + |M \cap M'| = |M' - M| + |M \cap M'| = |M'|\,.\]
Thus, $M$ has maximal size.
\end{proof}

\begin{thm}{Maximal Matching Algorithm}\vspace*{-5mm}
\begin{myitemize}
  \item[\myi]   Set $M = \emptyset$.
  \item[\myii]  Search for an augmenting path $P$ for $M$.
  \item[\myiii] Replace $M$ by $M \oplus E(P)$.
  \item[\myiv]  Continue until there is no augmenting path.
  \item[\myv]   $M$ is a maximal matching.
\end{myitemize}
\end{thm}

In general, it is difficult to find augmenting paths efficiently
but for bipartite graphs it is easy.

\begin{thm}{Bipartite Augmenting Path Algorithm}
Let $B = (X \cup Y ,E_B)$ be a bipartite graph and let $M$ be a matching in $B$.
\begin{myitemize}
  \item[\myi]    If $M$ covers $X$, then $M$ is maximal; set $T = \emptyset$; end.
  \item[\myii]   Otherwise, set $T = \{v\}$ for some vertex $v \in X - V(M)$.
  \item[\myiii]  Let $2m$ be the longest path-length from $v$ in $T$.
  \item[\myiv]   Consider each $x \in V(T)$ at distance $2m$ from $v$.
  \item[\myv]    If $y \in N(x) - V(T) - V(M)$, then add edge $\{x,y\}$ to $T$; end.
  \item[\myvi]   If $y \in N(x) - V(T)$, then add edges $\{x,y\}$ and $\{y,x'\} \in M$ to $T$.
  \item[\myvii]  Repeat until $N(x) - V(T) = \emptyset$.
  \item[\myviii] Then $T$ contains an augmenting path starting from $v$ if one exists.
\end{myitemize}
\end{thm}

\definition
A \emph{directed graph} $D = (V,A)$ consists of vertices $V$ and arcs $A \subseteq V \times V$.\\
We can draw $D$ as dots and $A$ as arrows between the dots.

\example
Let $D$ be the directed graph $(V,A)$
with $V = \{1,2,3\}$ and $A = \{(1,2), (2,1), (2,3)\}$.
\begin{center}{\psset{unit=10mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,
  linecolor=gray,fillstyle=none,shadow=false,labelsep=8pt}\pspicture(0,-.75)(3.5,.75){\small\darkgray
  \cnode(0  ,0){.1}{a}\uput[180](0  ,0){1}
  \cnode(1.5,0){.1}{b}\uput[ 90](1.5,0){2}
  \cnode(3  ,0){.1}{c}\uput[  0](3  ,0){3}
  \ncarc[arcangleA=45,arcangleB=45]{-> }{a}{b}
  \ncarc[arcangleA=45,arcangleB=45]{-> }{b}{a}
  \ncline{-> }{b}{c}
 \psset{fillstyle=solid}\multips(0,0)(1.5,0){3}{\mydot}}\endpspicture}
 \end{center}


\definition
A \emph{network} is a directed graph $D = (V,A)$ with two distinguished vertices,
the \emph{source} $s$ and \emph{sink} $t$ (or \emph{terminal}),
and a \emph{capacity function} $c: A \to \RR_{\geq 0}$.

\definition
A \emph{flow} in $D$ is a function $f: A \to \RR_{\geq 0}$ such that
\begin{myitemize}
	\item $0 \leq f(a) \leq c(a)$ for each arc $a \in A$.
	\item $f^+ (v) = f^- (v)$ for each vertex $v \in V - \{s,t\}$, where
          \begin{align*}
            f^- (v) &= \sum_{u : (u,v) \in A} f(u,v)\\
            f^+ (v) &= \sum_{w : (v,w) \in A} f(v,w)\,.
          \end{align*}
\end{myitemize}
The \emph{strength} of $f$ is $|f| = f^+ (s) - f^- (s)$.


\definition
A \emph{cut} in $D$ is a bipartition $(X,Y)$ of $V$ with $s \in X$ and $t \in Y$.\\
The \emph{capacity} of a cut $(X,Y)$ is the sum
\[ c(X,Y) = \sum_{u \in X, v \in Y : (u,v) \in A} c(u,v)\,.\]

\newcommand{\hallvnea}[2]{\begin{center}{\psset{unit=10mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,
  linecolor=gray,fillstyle=none,shadow=false,labelsep=8pt}\pspicture(0,-.25)(3.5,1.65){#1
  \cnode(-1.5,.75){.1}{s}\cnode(0,0){.1}{a}\cnode(0,1.5){.1}{b}\cnode(1.5,1.5){.1}{c}\cnode(1.5,0){.1}{d}\cnode(3,.75){.1}{t}
  \uput[180](-1.5,.75){ s}\uput[0](3,.75){ t}
  \ncarc[arcangleA= 30,arcangleB= 30]{-> }{s}{b}\ncarc[arcangleA=-30,arcangleB=-30]{-> }{s}{a}
  \ncarc[arcangleA= 30,arcangleB= 30]{-> }{c}{t}\ncarc[arcangleA=-30,arcangleB=-30]{-> }{d}{t}
  \ncline{-> }{a}{b}\ncline{-> }{a}{d}\ncline{-> }{c}{d}\ncline{-> }{b}{c}}\psset{fillstyle=solid}
  \rput(-1.5,.75){\mydot}\rput(0,0){\mydot}\rput(0,1.5){\mydot}\rput(1.5,1.5){\mydot}\rput(1.5,0){\mydot}\rput(3,.75){\mydot}
  \rput(-.75,.4 ){\darkgray4}\rput(-.75,1.1){\darkgray3}
  \rput(-.25,.75){\darkgray3}\rput(1.75,.75){\darkgray1}
  \rput(.75,1.25){\darkgray6}\rput(.75, .25){\darkgray1}
  \rput( 2.25,.4){\darkgray3}\rput(2.25,1.1){\darkgray3}#2\endpspicture}\end{center}}
\newcommand{\hallvneav}[2]{\begin{center}{\psset{unit=10mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,
  linecolor=gray,fillstyle=none,shadow=false,labelsep=8pt}\pspicture(0,-1.1)(7,1.65){#1
  \cnode(-1.5,.75){.1}{s}\cnode(0,0){.1}{a}\cnode(0,1.5){.1}{b}\cnode(1.5,1.5){.1}{c}\cnode(1.5,0){.1}{d}\cnode(3,.75){.1}{t}
  \uput[180](-1.5,.75){ s}\uput[0](3,.75){ t}
  \ncarc[arcangleA= 30,arcangleB= 30]{-> }{s}{b}\ncarc[arcangleA=-30,arcangleB=-30]{-> }{s}{a}
  \ncarc[arcangleA= 30,arcangleB= 30]{-> }{c}{t}\ncarc[arcangleA=-30,arcangleB=-30]{-> }{d}{t}
  \ncline{-> }{a}{b}\ncline{-> }{a}{d}\ncline{-> }{c}{d}\ncline{-> }{b}{c}}\psset{fillstyle=solid}
  \rput(-1.5,.75){\mydot}\rput(0,0){\mydot}\rput(0,1.5){\mydot}\rput(1.5,1.5){\mydot}\rput(1.5,0){\mydot}\rput(3,.75){\mydot}
  \rput(-.75,.4 ){\darkgray4}\rput(-.75,1.1){\darkgray3}
  \rput(-.25,.75){\darkgray3}\rput(1.75,.75){\darkgray1}
  \rput(.75,1.25){\darkgray6}\rput(.75, .25){\darkgray1}
  \rput( 2.25,.4){\darkgray3}\rput(2.25,1.1){\darkgray3}#2\endpspicture}\end{center}}
\newcommand{\hallvneaa}{
  \rput(-1.02,-.05){3}\rput(-1.02,1.55){2}
  \rput(  .25, .75){2}\rput( 1.25, .75){1}
  \rput(  .75,1.75){4}\rput(  .75,-.25){1}
  \rput( 2.52,-.05){2}\rput( 2.52,1.55){3}}
\newcommand{\hallvneab}[1]{\rput[l](4,1.35){$\mathsf{|f|= \mathsf{f^+(s)-f^-(s)}}$}
  \rput[l](4.5,.79){$\meq{#1{\mathsf{2}+\mathsf{3}\black-\mathsf{0}}}$}
  \rput[l](4.5,.25){${#1{\meq\mathsf{5}}}$}}
\newcommand{\hallvneac}{{\psset{linecolor=lightgray,fillcolor=offwhite,fillstyle=solid}
  \psccurve(-1.6,.9)(1.9,1.7)(.2,-.3)
  \psccurve(1.38,-.1)(3.32,.89)(2.7,0)}}
\newcommand{\hallvnead}{\uput[270](0,0){$\mathsf u$}\uput[90](0,1.5){$\mathsf v$}
  \uput[90](1.5,1.5){$\mathsf w$}\uput[270](1.5,0){$\mathsf x$}
  \rput(-1.2,2){$X$}\rput(3.1,-.1){$Y$}}
\newcommand{\hallvneae}[3]{\rput(.75,.25){1}\rput(2.25,1.1){3}\rput(1.75,.75){1}
  {\psset{linecolor=blue,fillstyle=none}\ncarc[arcangleA=30,arcangleB=30]{-> }{c}{t}\ncline{-> }{c}{d}\ncline{-> }{a}{d}}
  \rput[l](2.2 ,2.2 ){{#1{${\mathsf{c}(X,Y)} = \mathsf{ c(u,x)+c(w,x)+c(w,t)}$}}}
  \rput[l](3.69,1.63){{#2{$= \mathsf{1+1+3}$}}}
  \rput[l](3.69,1.07){{#3{$= \mathsf{5}$}}}}

\example
\hallvnea{\hallvneac}{\hallvnead}
The strength of $f$ is $|f| = f^+ (s) - f^- (s) = 2 + 3 - 0 = 5$.\\
The cut $(X,Y)$ has capacity $c(X,Y)  = c(u,x) + c(w,x) + c(w,t) = 1 + 1 + 3 = 5$.

\definition
Let $(X,Y)$ be a partition of $D$ and $f$ be a flow on $D$.
Define
\[ f(X,Y):= \sum_{u \in X, v \in Y : (u,v) \in A} f(u,v)\,.\]

\begin{thm}{Theorem}
If $(X,Y)$ is a cut of $D$, then $|f| =f(X,Y) - f(Y,X)$.
\end{thm}

\begin{proof}
By definition, $f^+ (v) - f^- (v) = 0$ for all $v \in X-\{s\}$.
Therefore,
\begin{align*}
	|f| & = f^+ (s) - f^- (s)\\
	& = \sum_{u \in X} f^+ (u) - \sum_{v \in X} f^- (v)\\
	& = \sum_{u \in X} \sum_{v : (u,v) \in A} f(u,v) - \sum_{v \in X} \sum_{u : (u,v) \in A} f(u,v)\\
	& = \sum_{\substack{ u,v \in X:\\ (u,v) \in A}} f(u,v) + \sum_{\substack{u \in X, v \in Y:\\ (u,v) \in A}} f(u,v) - \sum_{\substack{v,u \in X:\\(u,v) \in A}} f(u,v) - \sum_{\substack{v \in X, u \in Y:\\(u,v) \in A}} f(u,v)\\
	& = f(X,Y)  -f(Y,X).\qedhere
\end{align*}
\end{proof}

\begin{thm}{Theorem}
For each flow $f$ and each cut $(X,Y)$ in $D$, $|f| \leq c(X,Y)$.
\end{thm}

\begin{proof}
From the previous theorem,
	\[ |f| = f(X,Y) - f(Y,X) \leq f(X,Y) \leq c(X,Y)\,.\qedhere\]
\end{proof}

\corollary
$|f| = f^- (t) - f^+ (t)$.

\begin{proof}
$|f| = f(V-\{t\}, \{t\}) - f(\{t\}, V-\{t\}) = f^- (t) - f^+ (t)$.
\end{proof}

\definition
Let $f$ be a flow on the network $D = (V,A)$.
An \emph{augmenting path} $P$ for $f$ is
a sequence of vertices $v_0, v_1, \ldots, v_n \in V$ for which either
\begin{myitemize}
	\item $e = (v_i, v_{i+1}) \in A$ and $\alpha_i = c(e) - f(e) > 0$, or
	\item $e = (v_{i+1}, v_i) \in A$ and $\alpha_i = f(e) > 0$.
\end{myitemize}
Define $\alpha = \min\{\alpha_i\}$ and let $f \oplus P$ denote the function given on $A$ by
\[
  (f \oplus P)(e) =
  \begin{cases}
    f(e) + \alpha, & e = (v_i, v_{i+1}) \in A\\
	f(e) - \alpha, & e = (v_{i+1}, v_i) \in A
  \end{cases}
\]

\begin{thm}{Theorem}
If $f$ has an augmenting path $P$ from $s$ to $t$,
then $f \oplus P$ is a flow with $|f \oplus P| > |f|$.
\end{thm}

\begin{proof}
It is easy to check that $f \oplus P$ satisfies the two flow conditions.\\
Furthermore, $|f \oplus P| = |f| + \alpha > |f|$ where $\alpha$ is defined as above.
\end{proof}

\corollary
If $f$ is a maximal flow (i.e. has maximal strength $|f|$),
then there is no augmenting path for $f$ from $s$ to $t$.

\begin{thm}{The Max-Flow Min-Cut Theorem (Ford and Fulkerson 1955)}
\[ \max |f| = \min c(X,Y)\,.\]
\end{thm}

\begin{proof}
Let any $f$ be a maximal flow in $D$ and
let $S$ be the set of all vertices reachable by an augmenting path for $f$ starting in $s$.
By the corollary above, $f$ has no augmenting path from $s$ to $t$.
Thus, $t \in T$, where $T = V-S$, so $(S,T)$ is a cut.
Let $u \in S$ and $v \in T$.

Suppose that $e = (u,v) \in A$.
Since $v$ cannot extend any augmenting path ending in $u$, $f(e) = c(e)$.

Suppose then that $e = (v,u) \in A$.
Since $v$ cannot extend any augmenting path ending in $u$, $f(e) = 0$.
Hence, by the corollary above,
\[
  |f| = f(S,T) - f(T,S)
      = \sum_{\substack{u \in S, v \in T:\\(u,v) \in A}} f(u,v) - \sum_{\substack{u \in S, v \in T:\\(v,u) \in A}} f(u,v)
      = \sum_{\substack{u \in S, v \in T:\\(u,v) \in A}} c(u,v)
      = c(S,T)\,.
\]
Hence, $\min c(X,Y) \leq c(S,T) \leq |f|$.

However, a theorem above states that $|f| \leq c(X,Y)$ for any cut $(X,Y)$.
Thus, $|f| = \min c(X,Y)$.
\end{proof}

\begin{thm}{The Ford-Fulkerson Algorithm (1960)}\vspace*{-5mm}
\begin{myitemize}
	\item[\myi]   Set $f = 0$.
	\item[\myii]  Search for an augmenting path $P$ for $f$ from $s$ to $t$.
	\item[\myiii] Replace $f$ by $f \oplus P$.
	\item[\myiv]  Continue until there is no augmenting path.
	\item[\myv]   Then $f$ is a maximal flow.
\end{myitemize}
\end{thm}

\begin{thm}{Theorem}
Each network with all-integer capacities has integer-valued maximal flow.
\end{thm}

\begin{proof}
Starting with the zero flow $f = 0$,
augment $f$ with augmenting paths from $s$ to $t$,
until $f$ is a maximal flow.
At each step, the values $f(e)$ change by the integers $0$ or $\pm \alpha$.
\end{proof}

We now use these ideas to prove K\"onig's Theorem
(and hence also Hall's and Dilworth's Theorems).

\begin{thm}{K\"onig's Theorem (1916)}
The maximal size $M$ of a partial transversal in a $(0,1)$-matrix $N$ equals\\
the minimal number $m$ of lines needed to cover all 1-entries of $N$.
\end{thm}

\begin{proof}
Let $R$ and $C$ be the row and column indices of $N$.\\
Define network $D = (V,A)$ with\vspace*{-2mm}
\begin{align*}
  V &= R \cup C \cup \{s,t\}\\
  A &= S \cup B \cup T \\[2mm]\text{where}\quad
  S &= \{s\} \times R\\
  B &= \{(i,j) \in R \times C : n_{ij} = 1\}\\
  T &= C \times \{t\}
\end{align*}
with capacities $c(e) = M + 1$ if $e \in B$ and $c(e) = 1$ otherwise.
Then there is a maximal flow $f$ with $f(e) \in \{0,1\}$ for all edges $e \in A$.
Therefore, the arcs $e \in B$ with positive flow ($f(e) = 1$)
are vertex-disjoint and correspond to a partial transversal of $A$.

Hence, by the Max-Flow Min-Cut Theorem,
$M \geq \min c(X,Y)$.\\
Let $(X,Y)$ be a minimal edge cut.
Since $c(X,Y) = \max |f| < M+1$,
no edge of $B$ is cut by $(X,Y)$,
so $c(X,Y) = |C|$,
where $U = (R \cap Y) \cup (C \cap X)$ is a set of vertices touching all edges of $B$.

Thus, $U$ corresponds in $N$ to a set of lines covering of 1-entries.
Hence, $m \leq |U| = c(X,Y) \leq M$.
Since $m \geq M$, we have equality.
\end{proof}


\section*{Spanning Trees}

\definition
A \emph{tree} is a connected graph containing no cycle.\\
A \emph{spanning tree} of a graph $G$ is a subgraph of $G$ that is a tree containing all vertices of $G$.

\begin{thm}{Theorem}
Every tree on $n$ vertices has $n-1$ edges.
\end{thm}

\begin{proof}
We can build up a tree by starting with a single vertex
and adding edges to the existing graph.
The single vertex has 1 vertex and 0 edges.
Each added edge adds just one vertex,
so the final tree will have one fewer edges than vertices.
\end{proof}

\begin{thm}{Theorem}
The spanning trees of a connected graph have the same number of edges.
\end{thm}

\begin{proof}
If $G$ is a connected graph on $n$ vertices,
then any spanning tree $T$ of $G$ will contain all $n$ vertices.
Hence, $T$ has $n-1$ edges.
\end{proof}

\begin{thm}{Theorem}
Every connected graph contains a spanning tree.
\end{thm}

\begin{proof}
Let $G$ be a connected graph.
If $G$ is a tree, then $G$ is a spanning tree for itself.\\
If $G$ is not a tree, then $G$ contains at least one cycle.
Remove an edge from a cycle in $G$.\\
The resulting graph is still connected and contains all vertices of $G$.

Continue to remove an edge from each cycle until no cycles remain.\\
The resulting graph is a tree containing all vertices of $G$.
In other words, it is a spanning tree of $G$.
\end{proof}

\begin{thm}{Theorem}
A connected graph on $n$ vertices is a tree if and only if it has $n-1$ edges.
\end{thm}

\begin{proof}
Let $G$ be a connected graph with $n$ vertices.
If $G$ is a tree, then it has $n-1$ edges.

Conversely, suppose that $G$ has $n-1$ edges.
Let $T$ be a spanning tree of $G$.
Then $T$ is contained in~$G$ and has as many vertices and edges as $G$.
Therefore, $T$ is in fact equal to $G$.
Hence, $G$ is a tree.
\end{proof}

\definition
A \emph{weighted graph} $G$ is a graph whose edges have been assigned numbers.\\
The \emph{weight} of an edge $e$ is denoted by $w(e)$.\\
The \emph{weight} $w(G)$ of $G$ is the sum of edge weights in $G$.\\
A \emph{minimal spanning tree} $T$ of $G$ is
a spanning tree with minimal weight $w(T)$ among all such trees of~$G$.

\begin{thm}{The Greedy Algorithm}\vspace*{-5mm}
\begin{myitemize}
	\item[\myi]   Set $T = \emptyset$.
	\item[\myii]  Let $A$ be the edges in $E-E(T)$ that form no cycle with edges in $T$.
	\item[\myiii] Choose an edge $e$ from $A$ that has smallest weight.
	\item[\myiv]  Add $e$ to $T$.
	\item[\myv]   Continue until $T$ has $n-1$ edges.
	\item[\myvi]  Then $T$ is a minimal spanning tree for $G$.
\end{myitemize}
\end{thm}

\definition
Let $G$ be a connected graph with positive edge-weights and let $a \in V(G)$.\\
Consider a shortest path from $a$ to $v$ for each vertex $v$ in $G$
(a shortest path is one with minimal weight).\\
A \emph{minimal $a$-path spanning tree} for $G$ is a union of such paths to form a spanning tree.

\remark
A minimal $a$-path spanning tree is \emph{not} generally a minimal spanning tree.

\example
\newcommand{\minnotminexa}[3]{{\psset{unit=12mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,
    linecolor=gray,fillstyle=solid,shadow=false}\pspicture(1.5,-.65)(7.5,2.3)\darkgray
  \put(0  ,0){\pspicture(0,0)(2,2)\minnotminexba#1\minnotminnodes\endpspicture}
  \put(3.5,0){\pspicture(0,0)(2,2)\minnotminexba#2\minnotminnodes\endpspicture}
  \put(7  ,0){\pspicture(0,0)(2,2)\minnotminexba#3\minnotminnodes\endpspicture}\endpspicture}}
\newcommand{\minnotminexba}{\pnode(1,2){a}\pnode(0,1){b}\pnode(1,1){c}\pnode(2,1){d}\pnode(1,0){e}
  \ncline{-}{a}{c}\Bput[.06]{1}\ncline{-}{a}{d}\Aput[.08]{4}\ncline{-}{c}{e}\Aput[.06]{1}}
\newcommand{\minnotminexbaa}{\ncline{-}{a}{b}\Bput[.08]{5}\ncline{-}{b}{c}\Bput[.06]{2}
  \ncline{-}{b}{e}\Bput[.08]{1}\ncline{-}{c}{d}\Aput[.06]{5}\ncline{-}{d}{e}\Aput[.08]{4}
  \uput[d](1,-.25){$G$}}
\newcommand{\minnotminexbab}{\ncline{-}{b}{e}\Bput[.08]{1}\uput[d](1,-.25){$T_1$}}
\newcommand{\minnotminexbac}{\ncline{-}{b}{c}\Bput[.08]{2}\uput[d](1,-.25){$T_2$}}
\newcommand{\minnotminnodes}{\nodea\nodeb\nodec\noded\nodee
                             \nput[labelsep=.25]{90}{a}{$\mathsf{a}$}}

\begin{center}
\minnotminexa{\minnotminexbaa}{\minnotminexbab}{\minnotminexbac}
\end{center}
The tree $T_1$ below  is a minimal spanning tree in $G$
whereas $T_2$ is a minimal $\mathsf{a}$-path spanning tree in $G$.

\begin{thm}{Dijkstra's Algorithm (1959)}\vspace*{-5mm}
\begin{myitemize}
  \item[\myi]   Set $T = \{a\}$.
  \item[\myii]  Let $A$ be the edges with one vertex $v$ not in $T$ and the other int $T$.
  \item[\myiii] Choose and edge $e$ from $A$ that gives a shortest path from $a$ to any $v$.
  \item[\myiv]  Add $e$ to $T$.
  \item[\myv]   Continue until $T$ contains all vertices of $G$.
  \item[\myvi]  Then $T$ is a minimal $a$-path spanning tree for $G$.
\end{myitemize}
\end{thm}

\begin{proof}
It is easy to see that $T$ is a spanning tree.
We must therefore show that the distances given by $T$ from $a$
to each vertex $v$ indeed equal $d(a,v)$ in $G$, where,
for any vertices $w,x \in V(G)$, $d(w,x)$ denotes the shortest distance between them.

Assume that this is not true - that the algorithm fails,
and let $v$ be the first vertex for which this happens.
Let $T'$ be the tree generated up until this point,
and let $u$ be the vertex preceding $v$ in $T'$.
Let $P$ be a shortest path from $a$ to $v$,
and let $z$ be the first vertex along this path that is not in $T'$.

Also, let $y$ be the preceding vertex in $P$.
Since the algorithm first failed with $v$ and $v$
was chosen to be in $T'$ and $z$ was not, we have
\begin{align*}
	d(a,v) & < d(a,u) + w(u,v)\\
	& \leq d(a,y) + w(y,z)\\
	& < d(a,y) + d(y,v)\\
	& = d(a,v)\,,
\end{align*}
which is clearly a contradiction.
\end{proof}


\newpage
\section*{Traversing Circuits}

\definition
The \emph{degree} $\deg(v)$ of a vertex $v$ is the number of edges that contain $v$.

\begin{thm}{Handshaking Lemma}
\[ 2 |E| = \sum_{v \in V} \deg(v)\]
\end{thm}

\begin{proof}
\[
     2|E|
   = \sum_{e \in E} 2
   = \sum_{e \in E} \sum_{v \in e} 1
   = \sum_{v \in V} \sum_{e \in E : v \in e} 1
   = \sum_{v \in V} \deg(v).\qedhere\]
\end{proof}

\example
By this lemma, no graph with five vertices can have degrees 3,3,3,2,2.

\lemma
Each vertex degree is at most $n-1$.

\example
By the above lemma, no graph with five vertices can have degrees 5,4,3,2,1, or 4,3,3,1,1.

\lemma
Suppose that $G$ is connected.
Then
\begin{myitemize}
  \item $G$ is a cycle if and only if each vertex in $G$ has degree~2.
  \item $G$ is a path  if and only if each vertex in $G$ has degree~2,
        except two with degree~1.
\end{myitemize}

\definition
Let $G$ be a connected graph.\\
An \emph{Euler trail}    in $G$ is a nonclosed walk passing each edge   of $G$ exactly once.\\
An \emph{Euler circuit}  in $G$ is a closed    walk passing each edge   of $G$ exactly once.\\
A  \emph{Hamilton path}  in $G$ is a path      that passes  each vertex of $G$ exactly once.\\
A  \emph{Hamilton cycle} in $G$ is a cycle     that passes  each vertex of $G$ exactly once.


\example
\newcommand{\edgab}{\ncline{-}{a}{b}}
\newcommand{\edgac}{\ncline{-}{a}{c}}
\newcommand{\edgad}{\ncline{-}{a}{d}}
\newcommand{\edgae}{\ncline{-}{a}{e}}
\newcommand{\edgbc}{\ncline{-}{b}{c}}
\newcommand{\edgbd}{\ncline{-}{b}{d}}
\newcommand{\edgbe}{\ncline{-}{b}{e}}
\newcommand{\edgcd}{\ncline{-}{c}{d}}
\newcommand{\edgce}{\ncline{-}{c}{e}}
\newcommand{\edgde}{\ncline{-}{d}{e}}

\newcommand{\verta}{\nput[labelsep=0]{0}{a}{\mydot}}
\newcommand{\vertb}{\nput[labelsep=0]{0}{b}{\mydot}}
\newcommand{\vertc}{\nput[labelsep=0]{0}{c}{\mydot}}
\newcommand{\vertd}{\nput[labelsep=0]{0}{d}{\mydot}}
\newcommand{\verte}{\nput[labelsep=0]{0}{e}{\mydot}}
\newcommand{\eulervert}{\verta\vertb\vertc\vertd\verte}

\newcommand{\eulerex}[2]{\begin{center}
  \psset{unit=12mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,
    linecolor=gray,fillstyle=solid,shadow=false}
  \pspicture(-4.25,-3)(8,1.5)
  \rput(-2,0.3){\pspicture(-1,-.309)(3,1.5)
    \pnode(0,0){a}\pnode(1,0){b}\pnode(2,0){c}\pnode(.5,.866){d}\pnode(1.5,.866){e}
    \edgad\edgae\edgbd\edgbe\edgcd\edgce\eulervert
    #1\nput[labelsep=.2]{270}{a}{\darkgray1}
      \nput[labelsep=.2]{270}{b}{\darkgray2}
      \nput[labelsep=.2]{270}{c}{\darkgray3}
      \nput[labelsep=.2]{ 90}{d}{$\darkgray\mathsf{u}$}
      \nput[labelsep=.2]{ 90}{e}{$\darkgray\mathsf{v}$}\endpspicture}
  \rput(3.75,0.3){\pspicture(-1,-.809)(1,1)
    \pnode(0,1){a}\pnode(.951,.309){b}\pnode(.588,-.809){c}\pnode(-.588,-.809){d}\pnode(-.951,.309){e}
    \edgab\edgac\edgad\edgae\edgbc\edgbd\edgbe\edgcd\edgce\edgde\eulervert#2
    \nput[labelsep=.2]{ 90}{a}{\darkgray1}
    \nput[labelsep=.2]{ 18}{b}{\darkgray2}
    \nput[labelsep=.2]{306}{c}{\darkgray3}
    \nput[labelsep=.2]{234}{d}{\darkgray4}
    \nput[labelsep=.2]{168}{e}{\darkgray5}
  \rput(-5.4,-2.5){\begin{tabular}{l}
    $u1v2u3v$ is an Euler trail.\\
    There is no Euler circuit.\\
    $1u2v3$ is a Hamilton path.\\
    There is no Hamilton cycle.
  \end{tabular}}
  \rput(.6,-2.5){\begin{tabular}{l}
    There is no Euler trail.\\
    $12345135241$ is an Euler circuit.\\
    $12345$ is a Hamilton path.\\
    $123451$ is a Hamilton cycle.
  \end{tabular}}


    \endpspicture}\endpspicture
  \end{center}}
\eulerex{}{}



\newpage
\begin{thm}{Theorem}
$G$ has an Euler circuit if and only if each vertex of $G$ has even degree.
\end{thm}

\begin{proof}
Suppose that $G$ has an Euler circuit $C$.
Each time $C$ passes via a vertex $v$, it uses 2 edges, one in and one out.
Every edge is used exactly one, so $\deg(v)$ is twice
the number of times $C$ passes through $v$.
Thus, $\deg(v)$ is even.

Conversely, suppose that each vertex in $G$ has even degree.
If $G$ has at least one edge, then some vertex has at least two edges.
Let $P = v_1, \ldots, v_k$ be a maximal path in $G$.
Since $\deg(v_k) \geq 2$,
there is an edge $\{v_k, v\}$ in $G$ where $v \neq v_{k-1}$.
Since $P$ is maximal, $v$ must lie in $P$
- in other words, $v = v_j$ for some $j$.
Then $C = v_j, \ldots, v_k, v_j$ is a cycle in $G$.

Let $G'$ be the graph obtained from $G$ by removing the edges of~$C$.
Then each vertex degree in $G'$ is even.
As long as edges remain, we can thus continue to find and remove cycles.
Hence, $G$ is a union of edge-disjoint cycles.
Since $G$ is connected, no cycle is vertex-disjoint from all other cycles.
Hence, we can traverse the cycles recursively to get an Euler circuit.
\end{proof}

\begin{thm}{Theorem}
$G$ has an Euler trail if and only if exactly two vertices have odd degree.
\end{thm}

\begin{proof}
Suppose that $G$ has an Euler trail $v_1,\ldots, v_k$.
Add the edge $\{v_k, v_1\}$ to $G$.\\
Now $G$ has an Euler circuit, so each vertex degree is even.
Remove the edge $\{v_k, v_1\}$ again.\\
Then each vertex degree is even,
except $\deg(v_1)$ and $\deg(v_k)$.

The converse is proved similarly.
\end{proof}

\begin{thm}{Algorithm}\vspace*{-5mm}
\begin{myitemize}
  \item[\myi]   Set $C = v_0$ for some vertex $v_0$ in $G$.
  \item[\myii]  Choose a cycle $C'$ with at least one vertex $v$, but no edge, of $C$.
  \item[\myiii] Replace one of the $v$'s in $C$ by $C'$.
  \item[\myiv]  Continue this process until $C$ contains all edges in $G$.
  \item[\myv]   Then $C$ is an Euler circuit in $G$.
\end{myitemize}
\end{thm}

In the following theorem, suppose that $G= (V,E)$ is simple with $n = |V| \geq 3$.

\begin{thm}{Dirac's Theorem (1962)}
If $\deg(v) \geq \frac{n}{2}$ for all $v \in V$, then $G$ has a Hamilton cycle.
\end{thm}

\begin{proof}
Assume that the theorem is false.
Since the graph $K_V = \bigl(V, \binom{V}{2}\bigr)$ has a Hamilton cycle,\\
$G$ is contained in a graph $G'$ on $V$ that is maximal
with respect to having no Hamilton cycle.\\
Without loss of generality, we may assume that $G = G'$.

Since $G \neq K_V$, there are vertices $u,v \in V$
such that $\{u,v\} \not\in E$.
Let $G^+$ be the graph obtained by adding the edge $\{u,v\}$ to $G$.
By the maximality of $G$, $G^+$ has a Hamilton cycle,
and each Hamilton cycle of $G^+$ must contain $\{u,v\}$.
Therefore, $G$ has a Hamilton path $v_1, \ldots, v_n$ from $u=v_1$ to $v=v_n$.

Set $S = \{v_i : \{u, v_{i+1}\} \in E\}$
and $T = \{v_i : \{v_i, v\} \in E\}$.
Then, since $G$ is simple, $v \not\in S \cup T$, so $|S \cup T| < n$.
Assume that $v_i \in S \cap T$.
Then $v_1, \ldots, v_i, v_n, v_{n-1}, \ldots, v_{i+1}, v_1$ is a Hamilton cycle in $G$,
a contradiction.
Therefore, $|S \cap T| = 0$.
Hence,
\[
  n  =   \frac{n}{2} + \frac{n}{2}
    \leq \deg(u) + \deg(v)
	 =   |S| + |T|
	 =   |S \cup T| + |S \cap T| < n\,,
\]
a contradiction.
\end{proof}


\section*{Matroids}

\begin{thm}{Theorem (Birkhoff 1912)}
The number of ways to colour a map $M$ in $\lambda$ colours is
$P(M; \lambda)$ for some fixed polynomial $P(M;x)$.
\end{thm}

{\bfseries Recall} that $(E,\If)$ where $\If\subseteq \mathcal{P}(E)$ is a \emph{matroid} if and only if
\begin{myitemize}
  \item[{(I1)}] $\emptyset \in \If$.
  \item[{(I2)}] If $A \in \If$ and $B \subseteq A$, then $B \in \If$.
  \item[{(I3)}] If $A,B \in \If$ and $|A| < |B|$,
              then $A \cup \{a\} \in \If$ for some $a \in B - A$.
\end{myitemize}

\example
Given the matrix
\[ \begin{pmatrix}
     1 & 0 & 1 & 0 & 0 \\
     0 & 1 & 1 & 0 & 0 \\
     0 & 0 & 0 & 1 & 1
	\end{pmatrix}\]
the set of its columns induce a {\em vector matroid} determined by linear dependence,\\
for instance by any of the following representations, where each digit refers to the associated column:
\begin{myitemize}
 \item[] $\If$\emph{ndependent sets}:
            $\emptyset$,\,1,\,2,\,3,\,4,\,5,\,12,\,13,\,14,\,15,\,23,\,24,\,
            25,\,34,\,35,\,124,\,125,\,134,\,135,\,234,\,235\,.
  \item[] $\Bf$\emph{ases} (maximal independent sets): 124,\,125,\,134,\,234,\,235\,.
  \item[] $\Cf$\emph{ircuits} (minimally dependent sets): 123,\,45\,.
\end{myitemize}
%Such a matroid is a \emph{vector matroid}.

\example
The \emph{uniform matroid} $U_{r,n} = (E, \If)$ has
$|E| = n$ and $\If = \{A \subseteq E : |A| \leq r\}$.

\example
Let $\Af = \{A_i\}_{i \in \If}$ be a family of subsets of $E$.\\
The partial matching $\If$ of $\Af$ form the \emph{transversal matroid} $(E,\If)$
(see page~\pageref{I-axioms} for more details).

\example
Let $E$ be the edges of a graph $G$ and let $\If$ be the family of forests of $G$.\\
Then $M(G) = (E,\If)$ is the \emph{cycle matroid} of $G$.

\definition
Let $E$ be a finite set and $\Bf \subseteq \Pf(E)$ be a family of subsets of $E$.\\
The tuple $(E,\Bf)$ is a matroid if and only if
\begin{myitemize}
	\item[{(B1)}] $\Bf \neq \emptyset$.
	\item[{(B2)}] If $B_1, B_2 \in \Bf$ and $x \in B_1 - B_2$,
                  then $(B_1 - x) \cup \{y\} \in \Bf$ for some $y \in B_2 - B_1$.
\end{myitemize}

\example\\
$U_{r,n} = (E,\Bf)$ is a uniform matroid, where $\Bf = \{A \subseteq E : |A| =r\}$.\\
The maximal partial matchings $\Bf$ form the transversal matroid $(E,\Bf)$.\\
The spanning forests $\Bf$ of a graph $G$ define the cycle matroid $M(G) = (E,\Bf)$ of $G$.

\definition
Let $E$ be a finite set and $\Cf \subseteq \Pf(E)$ be a family of subsets of $E$.\\
The tuple $(E,\Cf)$ is a matroid if and only if
\begin{myitemize}
	\item[{(C1)}] $\emptyset \not\in \Cf$.
	\item[{(C2)}] If $C_1, C_2 \in \Cf$, then $C_1 \not\subset C_2$.
	\item[{(C3)}] If $C_1, C_2 \in \Cf$ are distinct and $e \in C_1 \cap C_2$,
                  then $C \subseteq (C_1 \cup C_2) -e$ for some $C \in \Cf$.
\end{myitemize}

\example\\
$U_{r,n} = (E,\Cf)$ is a uniform matroid, where $\Cf = \{A \subseteq E : |A| =r+1\}$.\\
The cycle edge sets $\Cf$ of a graph $G$ define the cycle matroid $M(G) = (E,\Cf)$ of $G$.

\begin{thm}{Theorem}
  The sets of axioms (I1-3), (B1-2), and (C1-3) are equivalent.
\end{thm}

\begin{proof}
We will merely prove that (C3) follows from (I1-3).\\
Let $(E, \If)$ be a matroid and let $\Cf$ be the minimal subsets not in $\If$.\\
Suppose that $C_1, C_2 \in \Cf$ are distinct and that $e \in C_1 \cap C_2$,
and assume that $(C_1 \cup C_2) - e \in \If$.

By construction, $C_2 - C_1 \neq \emptyset$,
so we may choose some $f \in C_2 - C_1$.
Now, $C_2$ is minimally not in $\If$, so $C_2 - f \in \If$.
Choose $I \in \If$ to be maximal so that $C_2 - f \subseteq I \subseteq C_1 \cup C_2$.
Note that $C_2 \not\subseteq I$, so $f \not\in I$.

Similarly, $C_1 \not\subseteq I$, so there exists $g \in C_1 - I$.
Since $f \not\in C_1$, the elements $f$ and $g$ are distinct, so
\[ |I| \leq |(C_1 \cup C_2) - \{f,g\}| = |C_1 \cup C_2| -2 < |(C_1 \cup C_2) - e|\,.\]

By (I3), $I \cup \{a\} \in \If$ for some $a \in (C_1 \cup C_2) - e$ not in $I$,
contradicting the maximality of $I$.\\
Hence, $(C_1 \cup C_2) - e$ is not in $\If$ and thus contains some $C \subseteq \Cf$.
\end{proof}

\noindent
From the theorem above, we see that
\begin{myitemize}
	\item[\mybullet] If $(E,\If)$ is a matroid,
            then its \emph{bases} $\Bf$ (maximal members of $\If$) satisfy (B1-2),\\
            and \emph{circuits} $\Cf$ (or minimal subsets not in $\If$) satisfy (C1-3).
	\item[\mybullet] If $(E,\Bf)$ is a matroid,
            then its \emph{independent sets} $\If$ (subsets of $\Bf$'s members) satisfy (I1-3),\\
            and its \emph{circuits} $\Cf$ (or minimal non-subsets of $\Bf$'s members).
	\item[\mybullet] If $(E,\Cf)$ is a matroid,
            then its \emph{independent sets} $\If$ (proper subsets of $\Cf$'s members) satisfy (I1-3),\\
            and its \emph{bases} $\Bf$ (or maximal proper subsets of $\Cf$'s members) satisfy (B1-2).
\end{myitemize}

\remark
There are a myriad of other equivalent ways in which to define matroids,
for instance via the \emph{rank function}
$r(A) := \max\{ |I| : I \subseteq A, I \in \If\}$.\\
The tuple $(E,r)$ is a matroid if and only if
\begin{myitemize}
  \item[{(R1)}] If $A \subseteq E$, then $0 \leq r(A) \leq |A|$.
  \item[{(R1)}] If $A \subseteq B \subseteq E$, then $r(A) \leq r(B)$.
  \item[{(R1)}] If $A,B \subseteq E$, then $r(A \cup B) + r(A \cap B) \leq r(A) + r(B)$.
\end{myitemize}

\begin{thm}{Theorem}
For a graph $G = (V,E)$, let $\Cf$ be its cycle edge sets.\\
Then $M(G) = (E,\Cf)$ is a matroid (the cycle matroid of $G$).
\end{thm}

\begin{proof}
The family $\Cf$ trivially satisfies (C1) and (C2).
Let $C_1, C_2 \in \Cf$ be distinct circuits of $G$ containing a shared edge~$e$.
Let $P_1$ and $P_2$ be the paths $C_1 -e$ and $C_2 - e$ respectively.
Since $C_1$ and $C_2$ are distinct, $P_1$ and $P_2$ must also be distinct.

Now, $P_1$ and $P_2$ have the same endpoints (the vertices of $e$),
so $P_1 \cup P_2$ is a closed walk containing a cycle.
The edge set $C$ of this cycle is contained in $(C_1 \cup C_2) - e$.
\end{proof}

\begin{thm}{The Greedy Algorithm For Matroids (Borvka 1926, Kruskal 1956)}
Let $M = (E,\If)$ be a matroid with weights $w(e)$ for each $e \in E$:
\begin{myitemize}
  \item[\myi]   Set $B = \emptyset$.
  \item[\myii]  Let $A$ be all elements $e$ in $E-B$ for which $B \cup \{e\} \in \If$.
  \item[\myiii] Choose an edge $e$ from $A$ with smallest weight $w(e)$.
  \item[\myiv]  Add $e$ to $B$.
  \item[\myv]   Continue until $A = \emptyset$.
  \item[\myvi]  Then $B$ is a minimally weighted basis for $M$.
\end{myitemize}
\end{thm}


\begin{proof}
By (I3), the algorithm will return a basis $B = \{e_1, \ldots, e_r\}$.
Assume that $w(B') < w(B)$ for some basis $B' = \{f_1, \ldots, f_r\}$ of $M$.
We may suppose that $w(e_1) \leq \ldots \leq w(e_r)$
and $w(f_1) \leq \dots \leq w(f_r)$.
Set $i = \min\{j: w(f_j) < w(e_j)\}$.

By (I3), there is some $j \in \{1,\ldots, i\}$
for which $\{e_1, \ldots, e_{i-1}\} \cup \{f_j\} \in \If$.
Also, $w(f_j) \leq w(f_i) < w(e_i)$.
However, this means that the algorithm would not have chosen $e_i$
at the $i^{th}$ step for $B$, a contradiction.
Thus, $B$ is a basis with minimal weight.
\end{proof}

Let $M = (E,r)$ be a matroid.

\begin{thm}{Edmond's Matroid Partition Theorem (1970)}
The set $E$ can be partitioned into $k$ independent sets
if and only if $k \cdot r(A) \geq |A|$ for all $A \subseteq E$.
\end{thm}

A special case of this result is Edmonds' Tree Partition Theorem.

\definition
Let $M = (E,r)$ be a matroid on $n = |E|$ elements.
For all $A \subseteq E$, define
\[ r^*(A) := |A| - r(E) + r(E-A)\,.\]
Then $M^* := (E,r^*)$ is a matroid,
called the \emph{dual matroid} of $M$.\\
Further, for $k=r(E)$ and all $i,j$, define
\begin{align*}
	f_i & = \max\{|A| : r(A) = i\}, & U & = \{f_0 + 1, \ldots, f_{k-1}+1\}\\
	f_j^* & = \max\{|A| : r^*(A) = j\}, & V & = \{n-f^*_{n-k-1}, \ldots, n-f_0^*\}\,.
\end{align*}

\begin{thm}{Britz et al. (2012)}\vspace*{-1mm}
  \[ U \cup V = \{1,\ldots, n\}\qquad\text{and}\qquad
     U \cap V = \emptyset\,.\vspace*{-1mm}\]
\end{thm}

\begin{proof}
Assume that the theorem is false.\\
Then $f_i +1 = n - f_j^*$ for some $i,j$.\\
Choose $A \subseteq E$ so that $|A| = f_j^*$ and $r^*(A) = j$.\\
Then $|E -A| = n-|A| = n-f_j^* = f_i +1$,
so $r(E-A) \geq i+1$.\\
By definition, $-|A| + r^*(A) + r(E) = r(E-A)$;
therefore $-f_j^* + j + k \geq i+1$.

Similarly, $n-f_i + i -k \geq j+1$.
Adding these inequalities gives $1 = n-f_i - f_j^* \geq 2$, a contradiction.
\end{proof}

The above theorem generalises Wei's Duality Theorem [Wei 1991],
a celebrated theorem in which similarly defined numbers described
the minimal weights of subcodes, by rank,
of a linear code and its dual.
The theorem also generalises a similar result for graphs proved by [Britz 2007].\\
(See lecture slides for more details.)

\newpage
\begin{thebibliography}{9}

\bibitem{aigner79} M.~Aigner,
{\sl Combinatorial Theory}, Springer-Verlag, New York, 1979.

%\bibitem{AiZi10}
%M.~Aigner and G.M.~Ziegler,
%{\sl Proofs from The Book}, 4th edition, Springer-Verlag, Berlin, 2010.

%\bibitem{bogomolny}
%A.~Bogomolny, {\sl Pigeonhole Principle}, \url{http://www.cut-the-knot.org/do_you_know/pigeon.shtml}, 2016--03.

\bibitem{BoMu76} J.A.~Bondy and U.S.R.~Murty,
{\sl Graph Theory with Applications}, Macmillan Press, New York, 1976.

%\bibitem{brandt01}
%J.~Brandt, {\sl Kombinatorik}, Aarhus University, lecture notes, 2001.

\bibitem{britz07a} T.~Britz,
Higher support matroids,
{\sl Discrete Math.}~{\bf 307} (2007), 2300--2308.

\bibitem{BrJoMaSh12} T.~Britz, T.~Johnsen, D.~Mayhew, and K.~Shiromoto,
Wei-type duality theorems for matroids,
{\sl Des.\ Codes Cryptogr.}~{\bf 62} (2012), 331--341.

\bibitem{FoFu62} L.R.~Ford, Jr.\ and D.R.~Fulkerson,
{\sl Flows in Networks}, Princeton Univ.\ Press, 1962.

\bibitem{GrGrLo95} R.L.~Graham, M.~Gr\"otschel, and L.~Lov\'asz (eds.),
{\sl Handbook of Combinatorics. I--II}, North-Holland, Amsterdam, 1995.

%\bibitem{GrRoSp90}
%R.L.~Graham, B.L.~Rothschild, and J.~Spencer,
%{\sl Ramsey Theory}, 2nd edition, John Wiley \&\ Sons, Inc., New York, 1990.

%\bibitem{LaRob14}
%B.M.~Landman and A.~Robertson,
%{\sl Ramsey Theory on the Integers}, 2nd edition, AMS, Providence, RI, 2014.

\bibitem{LoPl86} L.~Lov\'asz and M.D.~Plummer,
{\sl Matching Theory}, Akad\'emiai Kiad\'o, North Holland, Budapest, 1986.

%\bibitem{liu68} C.L.~Liu,
%{\sl Introduction to Combinatorial Mathematics}, McGraw-Hill Book Co., New York,~1968.

\bibitem{vLiWi92} J.H.~van Lint and R.M.~Wilson,
{\sl A Course in Combinatorics}, Cambridge University Press, 1992.

\bibitem{rado42} R.~Rado,
A theorem on independence relations,
{\sl Quart.\ J.~Math., Oxford Ser.}~{\bf 13} (1942), 83--89.

\bibitem{wei91} V.K.~Wei,
Generalized Hamming weights for linear codes,
{\sl IEEE Trans.\ Inform.\ Theory}~{\bf 37} (1991), 1412--1418.

\end{thebibliography}

\end{document}


%\definition
%A \emph{cutset} of a graph is a set of edges that separate the graph.
%A \emph{bond} is a minimal cutset.
%
%\noindent
%Let $G$ be a graph on $n$ edges, and set
%\begin{tabular}{rl}
%	$k=$ & the number of edges in a spanning forest of $G$.\\
%	$b_i = $& the minimum number of edges in $i$ bonds, non contained in the union of the others.\\
%	$c_j = $ the minimum numbers of edges in $j$ cycles, none contained in the union of the others.\\
%	$U =$ & $\{b_1, \ldots, b_k\}$.\\
%	$V = $ & $\{n+1-c_{n-k}, \cdots, n+1-c_1\}$.
%\end{tabular}
%
%\begin{thm}{Britz (2007)}
%  \[ U \cup V = \{1,\ldots, n\}\qquad\text{and}\qquad
%     U \cap V = \emptyset\,.\]
%\end{thm}
%
%\example
%\begin{center}
%\pspicture(0,0)(1,1.8)
%  \psset{unit=12mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,
%      linecolor=gray,shadow=false,fillstyle=none,dash=7pt 5pt}
%   \rput(1,1){\pspicture(0,0)(2,2)
%   \pscircle(1,1){1}
%   \psline(0,1)(2,1)
%   {\psset{fillstyle=solid}\rput(0,1){\mydot}\rput(1,2){\mydot}}
%   {\psset{fillstyle=solid}\rput(1,0){\mydot}\rput(2,1){\mydot}}
%  \endpspicture}
%\endpspicture
%\end{center}
%Here, $(b_1,b_2,b_3) = (2,3,5)$ and $(c_1,c_2) = (3,5)$,
%so $U = \{2,4,5\}$ and $V = \{1,3\}$.\\
%It is clear that $U \cup V = \{1,2,3,4,5\}$ and $U \cap V = \emptyset$.
%
%\bigskip
%
%Define the $k$ elements of $U$ to be minimal weights of
%the $k$-dimensional vector space generated by a linear code,
%and $V$ to be their duals, we have the following theorem.
%
%\begin{thm}{Wei's Duality Theorem} (1991)
%  \[ U \cup V = \{1,\ldots, n\}\qquad\text{and}\qquad
%     U \cap V = \emptyset\,.\]
%\end{thm}
