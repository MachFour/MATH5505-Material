\documentclass[a4paper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyhdr}
\usepackage{framed}
\usepackage{hyperref}
\usepackage{pstricks,pst-node,pst-plot}
%\usepackage[english]{babel}
%\usepackage{enumerate }
%\usepackage{mathrsfs}
%\usepackage{graphicx}

\newrgbcolor{white}{1 1 1}
\newrgbcolor{nearlywhite}{0.95 0.95 0.95}
\newrgbcolor{offwhite}{0.9 0.9 0.9}
\newrgbcolor{lightgray}{0.85 0.85 0.85}
\newrgbcolor{halfgray}{0.8 0.8 0.8}
\newrgbcolor{halfdarkgray}{0.4 0.4 0.4}

\expandafter\let\expandafter\oldproof\csname\string\proof\endcsname
\let\oldendproof\endproof
\renewenvironment{proof}[1][\proofname]{%
  \oldproof[\scshape \noindent {\bfseries \text{Proof}}]%
}{\oldendproof}

\newenvironment{myitemize}
{\vspace*{-1mm}
 \begin{itemize}
    \setlength{\itemsep}{1pt}
    \setlength{\parskip}{1pt}
    \setlength{\parsep}{0pt}}
{\end{itemize}
 \vspace*{-1mm}}

\setlength{\topmargin}{0mm}
\addtolength{\oddsidemargin}{-.8\oddsidemargin}
\addtolength{\evensidemargin}{-.8\evensidemargin}
\addtolength{\textwidth}{+.3\textwidth}
\addtolength{\textheight}{+.05\textheight}
\setlength{\itemsep}{25mm}

\newcommand{\algorithm} {\bigskip\noindent{\bf Algorithm.}\;\;}
\newcommand{\example} {\bigskip\noindent{\bf Example.}\;\;}
\newcommand{\exercise}{\bigskip\noindent{\bf Exercise.}\;\;}
\newcommand{\lemma}{\bigskip\noindent{\bf Lemma.}\;\;}
\newcommand{\proposition}{\bigskip\noindent{\bf Proposition.}\;\;}
\newcommand{\remark}{\bigskip\noindent{\bf Remark.}\;\;}
\newcommand{\definition}{\bigskip\noindent{\bf Definition.}\;\;}
\newcommand{\challenge}{\bigskip\noindent{\bf Challenge.}\;\;}
\newcommand{\corollary}{\bigskip\noindent{\bf Corollary.}\;\;}
\newcommand{\notation}{\bigskip\noindent{\bf Notation.}\;\;}

\newenvironment{thm}[1]{
	\begin{framed}
	\noindent
	{\bfseries #1}\\}{\setlength{\itemsep}{0pt}
	\end{framed}
}

\newcommand{\ph}{\phantom}
\newcommand{\Af}{\mathcal{A}}
\newcommand{\Bf}{\mathcal{B}}
\newcommand{\Cf}{\mathcal{C}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\FF}{\mathbb{F}}
\newcommand{\Ff}{\mathcal{F}}
\newcommand{\If}{\mathcal{I}}
%\newcommand{\mathbb{N}}{\mathbb{N}}
\newcommand{\Pf}{\mathcal{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\Xf}{\mathcal{X}}
\newcommand{\Yf}{\mathcal{Y}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\abs}[1]{\Bigl| #1 \Bigr|}
\newcommand{\lr}[1]{\Bigl( #1 \Bigr)}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\Span}{span}

\newcommand{\mybullet}{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillcolor=black,linecolor=black,framearc=.3,shadow=true}
  \pspicture(-.3,0)(.8,.4)\qdisk(.25,.2){.1}\pscircle*[linecolor=gray](.25,.2){.07}\endpspicture}

\newcommand{\nodea}{\nput[labelsep=0]{0}{a}{\mydot}}
\newcommand{\nodeb}{\nput[labelsep=0]{0}{b}{\mydot}}
\newcommand{\nodec}{\nput[labelsep=0]{0}{c}{\mydot}}
\newcommand{\noded}{\nput[labelsep=0]{0}{d}{\mydot}}
\newcommand{\nodee}{\nput[labelsep=0]{0}{e}{\mydot}}
\newcommand{\nodef}{\nput[labelsep=0]{0}{f}{\mydot}}
\newcommand{\nodeg}{\nput[labelsep=0]{0}{g}{\mydot}}
\newcommand{\nodeh}{\nput[labelsep=0]{0}{h}{\mydot}}
\newcommand{\nodei}{\nput[labelsep=0]{0}{i}{\mydot}}
\newcommand{\nodej}{\nput[labelsep=0]{0}{j}{\mydot}}

\newcommand{\edgeab}{\ncline{-}{a}{b}\Aput[.1 ]{5}\nodea\nodeb}
\newcommand{\edgeae}{\ncline{-}{a}{e}\Bput[.1 ]{3}\nodea\nodee}
\newcommand{\edgebc}{\ncline{-}{b}{c}\Aput[.1 ]{4}\nodeb\nodec}
\newcommand{\edgebe}{\ncline{-}{b}{e}\Aput[.08]{3}\nodeb\nodee}
\newcommand{\edgebi}{\ncline{-}{b}{i}\Bput[.1 ]{2}\nodeb\nodei}
\newcommand{\edgecd}{\ncline{-}{c}{d}\Aput[.1 ]{2}\nodec\noded}
\newcommand{\edgecf}{\ncline{-}{c}{f}\Bput[.06]{8}\nodec\nodef}
\newcommand{\edgecg}{\ncline{-}{c}{g}\Aput[.06]{3}\nodec\nodeg}
\newcommand{\edgedj}{\ncline{-}{d}{j}\Aput[.1 ]{1}\noded\nodej}
\newcommand{\edgeeh}{\ncline{-}{e}{h}\Bput[.1 ]{4}\nodee\nodeh}
\newcommand{\edgeei}{\ncline{-}{e}{i}\Aput[.08]{1}\nodee\nodei}
\newcommand{\edgefg}{\ncline{-}{f}{g}\Bput[.09]{2}\nodef\nodeg}
\newcommand{\edgefi}{\ncline{-}{f}{i}\Aput[.06]{3}\nodef\nodei}
\newcommand{\edgegj}{\ncline{-}{g}{j}\Bput[.06]{2}\nodeg\nodej}
\newcommand{\edgehi}{\ncline{-}{h}{i}\Bput[.1 ]{6}\nodeh\nodei}
\newcommand{\edgeij}{\ncline{-}{i}{j}\Bput[.1 ]{4}\nodei\nodej}

\newcommand{\mypicture}[1]{\pspicture(0,0)(0,0)\psset{unit=1cm,
 shadowcolor=offwhite,shadow=true,shadowangle=-45,linewidth=.03,linecolor=gray,
 fillcolor=lightgray,shadowsize=.15,framearc=.3}#1\endpspicture}

\newcommand{\myi}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny1}\endpspicture}}
\newcommand{\myii}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny2}\endpspicture}}
\newcommand{\myiii}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny3}\endpspicture}}
\newcommand{\myiv}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny4}\endpspicture}}
\newcommand{\myv}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny5}\endpspicture}}
\newcommand{\myvi}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny6}\endpspicture}}
\newcommand{\myvii}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny7}\endpspicture}}
\newcommand{\myviii}{{\psset{unit=6mm,dotscale=1.5,linewidth=.05,fillstyle=none,shadow=false}%
  \pspicture(-.3,0)(.8,.4)\pscircle(.25,.2){.25}\rput(.25,.2){\tiny8}\endpspicture}}

\newcommand{\mymatrix}[1]{\psset{unit=4mm,linewidth=.03,linecolor=gray,fillstyle=solid,fillcolor=offwhite,shadow=false,framearc=0}\pspicture(0,0)(6,4)
  \psframe(0,0)(7,5)#1\psframe[linecolor=gray,fillcolor=offwhite,linewidth=.03,fillstyle=none,framearc=0](0,0)(7,5)\endpspicture}

\newcommand{\twovector}[2]{\begin{pspicture}(-0.25,-.2)(0.25,0.2)
  \psframe[framearc=0,shadow=false,fillstyle=solid,fillcolor=lightgray](-0.25,-.2)(0.25,0.2)
  \rput(-0.1,0){#1}
  \rput( 0.1,0){#2}\end{pspicture}}
\newcommand{\twomatrix}[4]{\begin{pspicture}(-0.25,-.35)(0.25,0.35)
  \psframe[framearc=0,shadow=false,fillstyle=solid,fillcolor=lightgray](-0.25,-.35)(0.25,0.35)
  \rput(-0.1, 0.15){#1}
  \rput( 0.1, 0.15){#2}
  \rput(-0.1,-0.15){#3}
  \rput( 0.1,-0.15){#4}\end{pspicture}}

\newcommand{\ds}{\displaystyle}
\newcommand{\mydot}{\pscircle(0,0){.1}}

\pagestyle{fancyplain}

\title{\Large\sc Chapter 3: Enumerative Combinatorics}
\author{Thomas Britz}
\date{}

\begin{document}

\maketitle
\lhead{MATH5505}
%\rhead{Combinatorics}
\rhead{Enumerative Combinatorics}

\section*{The Inclusion-Exclusion Principle}

\begin{thm}{Inclusion-Exclusion Principle}
\[ \Bigl|\bigcup_{i \in I} A_i\Bigr| = \sum_{J \subseteq I} (-1)^{|J| +1} \Bigl|\bigcap_{j
\in J} A_j\Bigr|\]
\end{thm}

For instance,
\[ |A| + |B| = |A \cup B| + |A \cap B|\]
or equivalently,
\[ |A \cup B| = |A| + |B| - |A \cap B|\]
and
\[ |A \cup B \cup C| = |A| + |B| + |C| - |A \cap B| - |A \cap C| - |B \cap C| + |A \cap B
\cap C|\,.\]

\lemma
\[ \sum_{J \subseteq I} t^{|J|} = (t+1)^{|I|}\]

\begin{proof}
If $I = \emptyset$, then the sum is just the term $t^{|\emptyset|} = 1$.
Otherwise, choose $i \in I$.
By induction on $|I|$,
\begin{align*}
     \sum_{J \subseteq I} t^{|J|}
  &= \sum_{i \in J \subseteq I} t^{|J|} + \sum_{ i \not\in J\subseteq I} t^{|J|}\\
  &= \sum_{J \subseteq I - \{i\}} t^{|J \cup\{i\}|} + \sum_{J \subseteq I - \{i\}} t^{|J|}
   = (t+1) \sum_{J \subseteq I - \{i\}} t^{|J|}
   = (t+1)(t+1)^{|I| - 1}
   = (t+1)^{|I|}\,.\qedhere
\end{align*}
\end{proof}

\lemma
\[ \sum_{K \subseteq J \subseteq I} t^{|J|} = (t+1)^{|I-K|} t^{|K|}\]

\begin{proof}
	\[ \sum_{K \subseteq J \subseteq I} t^{|J|} = t^{|K|} \sum_{J' \subseteq I-K} t^{|J'|}
=
(t+1)^{|I-K|} t^{|K|}\qedhere\]
\end{proof}

\corollary
\[
     \sum_{K \subseteq J \subseteq I} (-1)^{|J|}
  = \begin{cases}
	  (-1)^{|K|} & \text{ if } K=I\\
		0        & \text{ otherwise}.
    \end{cases}
\]
In particular,
\[ \sum_{J \subseteq I} (-1)^{|J|}
  = \begin{cases}
		1 & \text{if } I=\emptyset\\
		0 & \text{otherwise}.
	\end{cases}
\]

\begin{proof}
%Without using induction, we have the following
\[
    \sum_{J \subseteq I} (-1)^{|J|}
  = \sum_{i \in J \subseteq I} (-1)^{|J|} + \sum_{i\not\in J \subseteq I} (-1)^{|J|}
  = \sum_{J \subseteq I - \{i\}} (-1)^{|J \cup \{i\}} + \sum_{J \subseteq I - \{i\}}
  (-1)^{|J|} = 0\qedhere
\]
\end{proof}
	
The first lemma generalises the observation that $I$ contains $2^{|I|}$ subsets.
It also generalises the following well-known result.

\begin{thm}{The Binomial Theorem}
	\[ (a+b)^n = \sum_{k=0}^n \binom{n}{k} a^k b^{n-k}\]
\end{thm}

\begin{proof}
Apply the above lemma to $t = \frac{a}{b}$. That is,
\[
    (a+b)^n
  = b^n \left(\frac{a}{b} + 1\right)^n
  = b^n \sum_{J \subseteq [n]} \Bigl(\frac{a}{b}\Bigr)^{|J|}
  = b^n \sum_{k=0}^n \binom{n}{k} \Bigl(\frac{a}{b}\Bigr)^k
  = \sum_{k=0}^n \binom{n}{k} a^k b^{n-k}\,.\qedhere
\]
\end{proof}

\medskip
\noindent
{\bfseries Inclusion-Exclusion Principle, Proof I.}
\begin{align*}
	  \Bigl| \bigcup_{i \in I} A_i \Bigr|
  & = \sum_{a \in \bigcup_{i \in I} A_i} 1
    = \sum_{a \in \bigcup_{i \in I} A_i} \Bigl(1 - \sum_{J \subseteq \{ j : a \in A_j\}}
    (-1)^{|J|}\Bigr)
    = \sum_{a \in \bigcup_{i \in I} A_i} \sum_{\emptyset \neq J \subseteq \{ j : a \in
    A_j\}} (-1)^{|J| +1}\\
  & = \sum_{\emptyset \neq J \subseteq I} \sum_{a \in \bigcap_{j \in J} A_j} (-1)^{|J|+1}
    = \sum_{\emptyset \neq J \subseteq I} (-1)^{|J| +1} \Bigl| \bigcap_{j \in J}A_j\Bigr|
    = \sum_{J \subseteq I} (-1)^{|J|+1} \Bigl| \bigcap_{j \in J} A_j \Bigr|\,.\qed
\end{align*}

\medskip
\noindent
{\bfseries Inclusion-Exclusion Principle, Proof II.}\\
Use the simple Inclusion-Exclusion Principle $|A \cup B| = |A| + |B| - |A \cap B|$ and
induction on $|I|$:
\begin{align*}
	    \Bigl| \bigcup_{i \in I} A_i \Bigr|
      = \abs{A_n \cup \bigcup_{i \in I-\{n\}} A_i}
	& = |A_n| + \abs{\bigcup_{i \in I - \{n\}} A_i} - \abs{A_n \cap \bigcup_{i \in I
-\{n\}} A_i}\\
	& = |A_n| + \abs{\bigcup_{i \in I-\{n\}} A_i} - \abs{\bigcup_{i \in I - \{n\}} A_i\cap
A_n}\\
	& = |A_n| + \sum_{J \subseteq I - \{n\}} (-1)^{|J|+1} \abs{\bigcap_{j \in J} A_j}
-\sum_{J \subseteq I - \{n\}} (-1)^{|J|+1} \abs{\bigcap_{j \in J} A_j \cap A_n}\\
	& = \sum_{J \subseteq I} (-1)^{|J|+1} \abs{\bigcap_{j \in J} A_j}\,.\qed
\end{align*}

Let $S$ be a set, $G$ an abelian group, and $\{A_i\}_{i \in I}$ be a finite family of
$S$-subsets.\\
A function $v : \Pf(S) \to G$ is a \emph{valuation} if, for all $A, B \subseteq S$,
	\[ v(A) + v(B) = v(A \cup B) + v(A \cap B)\,.\]

\begin{thm}{The Inclusion-Exclusion Principle (valuations)}
\[
    v\Bigl(\bigcup_{i \in I} A_i \Bigr)
  = \sum_{J \subseteq I} (-1)^{|J|+1} v\Bigl(\bigcap_{j \in J} A_j \Bigr)
\]
\end{thm}
	
\begin{proof}
Use induction on $|I|$:
\begin{align*}	
        v\Bigl(\bigcup_{i \in I} A-i\Bigr) & = v\Bigl(A_n \cup \bigcup_{i \in I=\{n\}}
        A_i\Bigr)\\
	& = v(A_n) + v\lr{\bigcup_{i \in I - \{n\}} A_i} - v\Bigl(\bigcup_{i \in I-\{n\}} A_i
\cap A_n\Bigr)\\
	& = v(A_n) + \sum_{J \subseteq I-\{n\}} (-1)^{|J|+1} v\lr{\bigcap_{j \in J} A_j}
      - \sum_{J\subseteq I-\{n\}} (-1)^{|J|+1} v\Bigl(\bigcap_{j \in J} A_j \cap
      A_n\Bigr)\\
	& = \sum_{J \subseteq I} (-1)^{|J|+1} v\Bigl(\bigcap_{j \in J} A_j\Bigr)\,.\qedhere
\end{align*}
\end{proof}

\begin{thm}{The Inclusion-Exclusion Principle (probabilities)}
For a probability $P : \Pf(S) \to [0,1]$,
	\[ P \Bigl(\bigcup_{i \in I} A_i\Bigr)
  = \sum_{J \subseteq I} (-1)^{|J|+1} P\Bigl(\bigcap_{j \in J} A_j\Bigr)\]
\end{thm}

\begin{proof}
$P(A) + P(B) = P(A \cup B) + P(A \cap B)$ for all $A,B \subseteq S$.
\end{proof}

\begin{thm}{The Inclusion-Exclusion Principle (weights)}
For $w: S \to G$, define $w: \Pf(S) \to G$ by $w(A) := \sum_{a \in A} w(a)$.
Then
	\[ w\lr{\bigcup_{i \in I} A_i} = \sum_{J \subseteq I} (-1)^{|J|+1} w\lr{\bigcap_{j \in
J}A_j}\]
\end{thm}

\begin{proof}
\begin{align*}
   w(A) + w(B)
&= \sum_{a \in A} w(a) + \sum_{a \in B} w(a)
 = \sum_{a \in A \cup B} w(a) + \sum_{a \in A \cap B} w(a)
 = w(A \cup B) + w(A \cap B)\,.\qedhere
\end{align*}
\end{proof}

\lemma
If $A$ and $B$ are disjoint and $v(\emptyset) = 0$, then $v(A \cup B) = v(A) + v(B)$.

\begin{proof}
\[   	v(A \cup B)
      = v(A) + v(B) - v(A \cap B)\\
	  = v(A) + v(B) - v(\emptyset)\\
	  = v(A) + v(B)\,.\qedhere
\]
\end{proof}

If each $A_i$ is finite, then each valuation $c$ on $\Pf(\bigcup A_i)$ is in fact a weight
function on the elements of $\bigcup A_i$, since $v(A_i) = \sum_{a \in A_i} v(a)$.
This is not true for uncountable sets.

\lemma
   \[ \sum_{J \subseteq I : |J| \geq r+1} (-1)^{|J|+1} = (-1)^r \binom{|I|-1}{r}\]

\begin{proof}
Suppose that $i \in I$.
Then
\begin{align*}
	\sum_{J \subseteq I : |J| \geq r+1} (-1)^{|J|+1} & = \sum_{ i \in J \subseteq I : |J|
\geq r+1} (-1)^{|J|+1} + \sum_{i \not\in J \subseteq I : |J| \geq r+1} (-1)^{|J|+1}\\
	& = \sum_{J \subseteq I - \{i\} : |J| \geq r} (-1)^{|J \cup \{i\}|+1} - \sum_{J
\subseteq I - \{i\} : |J| \geq r+1} (-1)^{|J|}\\
	& = \sum_{J \subseteq I - \{i\} : |J| = r} (-1)^{|J|}\\
	& = (-1)^r \binom{|I|-1}{r}\,.\qedhere
\end{align*}
\end{proof}

\begin{thm}{The Bonferroni Inequalities (Dunn 1959)}
For even $s$ and odd $t$ with $s,t \leq |I|$,
\[
  \sum_{J \subseteq I : |J| \leq s} (-1)^{|J|+1} \abs{\bigcap_{j \in J} A_j} \leq
  \abs{\bigcup_{i \in I} A_i} \leq \sum_{J \subseteq eq I : |J| \leq t} (-1)^{|J|+1}
  \abs{\bigcap_{j \in J} A_j}\,.
\]
\end{thm}

\begin{proof}
For each $a \in \bigcup_{i \in I} A_i$,
set $I_a := \{ i : a \in A_i\}$ and choose $i_a \in I_a$.
By the preceding lemma,
\begin{align*}
	\Delta
 := \abs{\bigcup_{i\in I} A_i} - \sum_{J \subseteq I :  |J| \leq r} (-1)^{|J|+1}
 \abs{\bigcap_{j \in J} A_j}
 &= \sum_{J \subseteq I : |J| \geq r+1} (-1)^{|J|+1} \abs{\bigcap_{j \in J} A_j}
  = \sum_{J \subseteq I : |J| \geq r+1} \sum_{a \in \bigcap_{j \in J} A_j} (-1)^{|J|+1}\\
 &= \sum_{a \in \bigcup_{i \in I} A_i} \sum_{ J \subseteq I_a : |J| \geq r+1} (-1)^{|J|+1}
  = (-1)^r \sum_{a \in \bigcup_{i \in I} A_i} \binom{|I_a| -1}{r}\,.
\end{align*}
Thus, $\Delta <0$ when $r$ is odd, and $\Delta > 0$ when $r$ is even.
The Inequalities follow.
\end{proof}

\definition
A \emph{derangement} is a permutation $\pi \in \Sigma_n$ with no fixed point $\pi(i) =
i$.\\
Here, $\Sigma_n$ denotes the set of permutations on $[n]$.

\proposition
The number of derangements of $n$ elements is
	\[ D_n := n! \sum_{i=0}^n \frac{(-1)^i}{i!}\,.\]

\begin{proof}
For $i \in I := [n]$, let $A_i$ be the set of permutations $\pi \in \Sigma_n$ with $\pi(i)
= i$.\\
Note that $|\Sigma_n| = n!$ and that $\bigl|\bigcap_{j \in J} A_j\bigr| = (n-|J|)!$ for
each $\emptyset \neq J \subseteq I$.\\
By the Inclusion-Exclusion Principle,
\begin{align*}
    D_n
  = \abs{\Sigma_n - \bigcup_{i \in I} A_i}
 &= n! - \sum_{J \subseteq I} (-1)^{|J|+1} \abs{\bigcap_{j \in J} A_j}\\
 &= n! + \sum_{\emptyset \neq J \subseteq I} (-1)^{|J|} (n-|J|)!
  = n! + \sum_{i=1}^n \binom{n}{i} (-1)^i (n-i)!
  = n! \sum_{i=0}^n \frac{(-1)^i}{i!}\,.\qedhere
\end{align*}
\end{proof}

\corollary
About $e^{-1}$ of all permutations are derangements.

\lemma
$D_n = (-1)^n + nD_{n-1}$.

\begin{proof}
\[ D_n = n! \frac{(-1)^n}{n!} + n(n-1)! \sum_{i=0}^{n-1} \frac{(-1)^i}{i!} = (-1)^n + n
D_{n-1}\,.\qedhere\]
\end{proof}

\corollary
Let $M$ be an $n \times n$ matrix with 0's on the diagonal and $\pm 1$ elsewhere.\\
If $n$ is even, then $\det M \neq 0$.

\begin{proof}
Let $\Delta_n$ be the set of derangements on $[n]$ and write $M = (m_{ij})$.
Then
\[
    \det M = \sum_{\pi \in \Sigma_n} \sgn(\pi) \prod_{i=1}^n m_{i\pi(i)}
  = \sum_{\pi \in\Delta_n} \prod_{i=1}^n m_{i\pi(i)}
  \equiv \sum_{\pi \in \Delta_n} 1 \equiv D_n \pmod{2}\,.
\]
By the above lemma, $D_n$ is odd for even $n$, so $\det M$ must also be odd.
\end{proof}

\corollary
The number of $2 \times n$ Latin rectangles is
	\[ n! \sum_{i=0}^n \frac{(-1)^i}{i!} \approx \frac{n!}{e}\,.\]
	
\begin{thm}{Theorem}
The number of integer solutions to $x_1 + \dots + x_n = k$ with $x_i \geq 0$ is
$\binom{n+k-1}{n-1}$.
\end{thm}

\begin{proof}
Draw $k$ dots in a row and draw $n-1$ lines between them.\\
Dots bordered by lines represent one of the $x_i$ values and vice versa.\\
Bijectively then, the number of solutions is the number of ways to draw these dots on
lines.
\end{proof}

\begin{thm}{Theorem}
The number of integers solutions to $x_1 + \dots + x_n = k$ with $0 \leq x_i < \ell$ is
\[ \sum_{i=0}^n (-1)^i \binom{n+k-\ell i -1}{n-1}\,.\vspace*{-2mm}\]
\end{thm}

\begin{proof}
Set $I:=[n]$ and let $S$ be the set of all non-negative integer solutions.
Let $A_i$ be the set of non-negative solutions with $x_i \geq \ell$ for $i \in I$.
For $j\subseteq I$, $\bigcap_{j \in J} A_j$ is the set of integer solutions with $x_j \geq
\ell$ for $j \in J$.
By substituting $y_j := x_j -\ell$ for each $j \in J$ and $y_j = x_j$ otherwise,
we get non-negative integer solutions to $y_1 + \dots + y_n = k - \ell |J|$.
There are $\binom{n+k - \ell |J| - 1}{n-1}$ non-negative integer solutions to this new
equation,
and thus, bijectively, that many solutions to the initial equation.

By the Inclusion-Exclusion Principle, the number of solutions is
\begin{align*}
	  \abs{S - \sum_{a \in \bigcup_{i \in I} A_i}}
  & = \binom{n+k-1}{n-1} - \sum_{J \subseteq I} (-1)^{|J|+1} \abs{\bigcap_{j \in J} A_j}\\
  & = \binom{n+k-1}{n-1} + \sum_{\emptyset \neq J \subseteq I}
  (-1)^{|J|}\binom{n+k-\ell|J|-1}{n-1}\\
  & = \binom{n+k-1}{n-1} \sum_{i=1}^n \binom{n}{i} (-1)^i \binom{n+k-\ell i -1}{n-1}\\
  & = \sum_{i=0}^n (-1)^i \binom{n+k-\ell i - 1}{n-1}\,.\qedhere
\end{align*}
\end{proof}

\definition
\emph{Euler's totient} $\phi(n)$ is the function given by
	\[ \phi(n) := \abs{\{i \in [n] : \gcd(n,i) = 1\}}\]

\example \vspace*{-3mm}
\begin{align*}
	\phi(8)  & = \bigl|\{1,3,5, 7\}\bigr|    = 4\\
	\phi(12) & = \bigl|\{1,5,7,11\}\bigr|    = 4\\
	\phi(7)  & = \bigl|\{1,2,3,4,5,6\}\bigr| = 6\,.
\end{align*}

\begin{thm}{Theorem}
	\[\phi(n) = n \prod_{p|n\,,\, p \text{ prime}} \lr{1- \frac{1}{p}}\]
\end{thm}

\begin{proof}
Write $n = p_1^{\alpha_1} \dots p_s^{\alpha_s}$,
where $p_i$ is prime and set $A_i = \{ m \in [n] : p_i | m\}$ for $i \in I :=[s]$.\\
For $J \subseteq I$, $\bigl|\bigcap_{j\in J} A_j\bigr| = \frac{n}{\prod_{j \in J} p_j}$.
By the Inclusion-Exclusion Principle,
\begin{align*}
     \phi(n)
   = \abs{[n]-\bigcup_{i \in I} A_i}
 & = n - \sum_{J \subseteq I} (-1)^{|J|+1} \abs{\bigcap_{j \in J} A_j}\\
 & = n + \sum_{\emptyset \neq J \subseteq I} (-1)^{|J|} \frac{n}{\text{$\ds\prod_{j \in J}
 p_j$}}
   = n \sum_{J \subseteq I} \prod_{j \in J}\frac{-1}{p_j}
   = n \prod_{i=1}^s \lr{1 - \frac{1}{p_i}}\,.\qedhere
\end{align*}
\end{proof}

\example
Using the above theorem,
\[
\begin{array}{rlcrl}
	\phi(8)   \hspace*{-2mm} & =    8(1 - \frac{1}{2}) = 4 &\qquad&
    \phi(7)   \hspace*{-2mm} & =    7(1 - \frac{1}{7}) = 6\\
	\phi(12)  \hspace*{-2mm} & =   12(1 - \frac{1}{2})(1 - \frac{1}{3}) = 4&\qquad&
	\phi(1000)\hspace*{-2mm} & = 1000(1 - \frac{1}{2})(1 - \frac{1}{5}) = 400
\end{array}
\]

\definition
Let $G = (V,E)$ be a graph.\\
A colouring $\chi : V \to [r]$ is \emph{proper} if $\chi(u) \neq \chi(v)$ whenever $\{u,v\}
\in E$.\\
Let $c(J)$ be the number of connected components in
the subgraph of $G$ with vertices $V$ and edges $J \subseteq E$.
%Then we have the following theorem.

\begin{thm}{Theorem (Birkhoff 1912)}
The number of proper $r$-colourings of $V(G)$ is $\ds P(G;r):= \sum_{J \subseteq E}
(-1)^{|J|} r^{c(J)}$.
\end{thm}

\begin{proof}
Let $C$ denote the set of all $r$-colourings of $V$.
Then $|C| = r^{|V|}$.
For $e = \{u,v\} \in E$, let $A_e$ be the colourings $\chi \in C$ with $\chi(U) =
\chi(V)$.
For each $J \subseteq E$, each colouring in $E_J:= \bigcap_{e \in J} A_e$ is monochromatic
in each
connected component of $(V, E_J)$ and the component colours are independent of each other.
Hence, $\bigl|\bigcap_{e \in J} A_e\bigr| = r^{c(A)}$.

By the Inclusion-Exclusion Principle, the number of proper colourings is
\begin{align*}
	\abs{C - \bigcup_{e \in E} A_e}
 & = r^{|V|} - \sum_{J \subseteq E} (-1)^{|J|+1}\abs{\bigcap_{j \in J} A_j}
   = r^{|V|} + \sum_{\emptyset \neq J \subseteq E} (-1)^{|J|} r^{c(J)}
   = \sum_{J \subseteq E} (-1)^{|J|} r^{c(J)}\,.\qedhere
\end{align*}
\end{proof}

\example
\[ P(K_n; r) = r(r-1)\dots(r-n+1)\]
Recursive identities allow efficient calculations of $P(G;r)$.



\section*{M\"obius Inversion}

Recall that a \emph{poset} $P$ is a set with a partial order $\preceq$ satisfying, for all
$x,y,z \in P$,
\begin{myitemize}
  \item[{(R)}] $x \preceq x$;
  \item[{(A)}] if $x \preceq y$ and $y \preceq x$, then $x = y$;
  \item[{(T)}] if $x \preceq y$ and $y \preceq z$, then $x \preceq z$.
\end{myitemize}

\definition
A \emph{lattice} $L$ is a poset with binary operators \emph{meet} $\wedge$ and \emph{join}
$\vee$ so that
\begin{myitemize}
	\item[\mybullet] $x \wedge y$ is the \emph{unique} maximal element smaller than both
$x$ and $y$.
	\item[\mybullet] $x \vee   y$ is the \emph{unique} minimal element greater than both
$x$ and $y$.
\end{myitemize}
A lattice is \emph{graded} if it has a well-defined rank function
	\[ \ell(x) := |C| - 1\]
where $C$ is any maximal chain with $\max(C) = x$.


\example
$[n]$ is a graded lattice under the usual order $\leq$ :
\hfill\mypicture{\psset{unit=6mm,dotscale=1.5,
  linewidth=.03,fillcolor=halfgray,linecolor=gray,shadowcolor=offwhite,shadow=true,shadowsize=.125,
  shadowangle=-45,dash=7pt 5pt}
  \rput(-5,-1.4){\pspicture(0,-.5)(0,3.5)
     \pscircle(0,3){.09}\psline(0,2.13)(0,2.87)\pscircle(0,2){.09}
     \psline(0,1.13)(0,1.87)
     \pscircle(0,1){.09}\psline(0,.13)(0,.87)\pscircle(0,0){.09}
     {\darkgray\small
      \rput(-.3,0){1}
      \rput(-.3,1){2}
      \rput(-.3,2){3}
      \rput(-.3,3){4}
      \rput( 0,-.75){$[4]$}}\endpspicture}}
\begin{align*}
	x \wedge y & = \min\{x,y\}\\
	x \vee   y & = \max\{x,y\}\\
	\ell(x)    & = x-1
\end{align*}


\example
$\Bf_n$ ($= \mathcal{P}(S)$) is a graded lattice under containment $\subseteq$ :
\hfill\mypicture{\psset{unit=6mm,dotscale=1.5,
  linewidth=.03,fillcolor=halfgray,linecolor=gray,shadowcolor=offwhite,shadow=true,shadowsize=.125,
  shadowangle=-45,dash=7pt 5pt}
  \rput(-5,-1.75){\pspicture(0,-.5)(0,3.5){\small\darkgray\pscircle(0,3){.09}
  \psline(-.91,2.09)(-.09,2.91)\psline(0,2.13)(0,2.87)\psline(.09,2.91)(.91,2.09)\pscircle(-1,2){.09}
  \pscircle(0,2){.09}\pscircle(1,2){.09}\psline(-1,1.13)(-1,1.87)\psline(-.91,1.09)(-.09,1.91)
  \psline(0,1.13)(0,1.87)\psline(.09,1.09)(.91,1.91)\psline(1,1.13)(1,1.87)\pscircle(-1,1){.09}
  \pscircle(0,1){.09}\pscircle(1,1){.09}{\psset{shadow=false}\psline(-.884,1.94)(.884,1.06)}
  \psline(-.91,.91)(-.09,.09)\psline(0,.13)(0,.87)\psline(.09,.09)(.91,.91)\pscircle(0,0){.09}
  \rput(0,-.4){$\emptyset$}\rput(-1.3,1){1}\rput(-.3,1){2}\rput(1.3,1){3}\rput(-1.4,2){13}
  \rput(-.4,2){12}\rput(1.4,2){23}\rput(0,3.4){123}}\rput(0,-1){$\mathcal{B}_3$}\endpspicture}}
\begin{align*}
	A \wedge B & = A \cap B\\
	A \vee   B & = A \cup B\\
	\ell(A)    & = |A|
\end{align*}


\example
The divisors of $n$ form a graded lattice under division $|$ :
\hfill\mypicture{\psset{unit=6mm,dotscale=1.5,
  linewidth=.03,fillcolor=halfgray,linecolor=gray,shadowcolor=offwhite,shadow=true,shadowsize=.125,
  shadowangle=-45,dash=7pt 5pt}
  \rput(-5,-1.75){\pspicture(0,-.5)(0,3.5){\small\darkgray
  \pscircle(1,3){.09}
  \psline(1.09,2.91)(1.91,2.09)
  \pscircle(0,2){.09}\pscircle(2,2){.09}
  \psline(-.91,1.09)(-.09,1.91)
  \psline(.09,2.09)(.91,2.91)\psline(0.09,1.91)(.91,1.09)\pscircle(-1,1){.09}
  \pscircle(1,1){.09}\psline(1.09,1.09)(1.91,1.91)
  \psline(-.91,.91)(-.09,.09)\psline(.09,.09)(.91,.91)\pscircle(0,0){.09}
  \rput(0,-.4){$1$}\rput(-1.3,1){3}\rput(1.3,1){2}\rput(2.3,2){4}
  \rput(-.4,2){6}\rput(1,3.4){12}}\rput(0.5,-1.25){$\{a:a\,|\,12\},\,|)$}\endpspicture}}
\begin{align*}
	a \wedge b & = \gcd(a,b)\\
	a \vee b   & = \lcm (a,b)\\
	\ell(a)    & = \sum_{i=1}^s \alpha_i, \text{ where } a = p_1^{\alpha_1} \dots
p_s^{\alpha_s}
\end{align*}


\example
The subspaces of a vector space form a graded lattice under containment $\subseteq$ :
%, for instance, consider subspaces of $\FF_2^2$,
\hfill\mypicture{\psset{unit=6mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,
  linecolor=gray,shadowcolor=offwhite,shadow=true,shadowsize=.125,shadowangle=-45,dash=7pt
  5pt}
  \rput(-1,-.4){\pspicture(0,-.5)(0,3.5){\tiny\darkgray
  \pscircle(0,2){.09}
  \psline(-.91,1.09)(-.09,1.91)
  \psline(0.09,1.91)(.91,1.09)\pscircle(-1,1){.09}
  \psline(0,1.09)(0,1.91)\pscircle(0,1){.09}\psline(0,.09)(0,.91)
  \pscircle(1,1){.09}
  \psline(-.91,.91)(-.09,.09)\psline(.09,.09)(.91,.91)\pscircle(0,0){.09}
  \rput( 0  ,-.4){\twovector{0}{0}}
  \rput(-1.5,1  ){\twovector{1}{0}}
  \rput(-.4 ,1  ){\twovector{1}{1}}
  \rput( 1.5,1  ){\twovector{0}{1}}
  \rput( 0  ,2.6){\twomatrix{1}{0}{0}{1}}}\rput(0,-1){Subspaces of
  $\mathbb{F}_2^2$}\endpspicture}}
\begin{align*}
	U \wedge V & = U \cap V\\
	U \vee   V & = \Span(U \cup V)\\
	\ell (U)   & = \dim(U)
\end{align*}


\example
The partitions $\pi_n$ of $[n]$ form a lattice under refinement $\preceq$ :
\hfill\mypicture{\psset{unit=6mm,dotscale=1.5,linewidth=.03,fillcolor=halfgray,
  linecolor=gray,shadowcolor=offwhite,shadow=true,shadowsize=.125,shadowangle=-45,dash=7pt
  5pt}
  \rput(-5,-.35){\pspicture(0,-.5)(0,3.5){\tiny\darkgray
  \pscircle(0,2){.09}
  \psline(-.91,1.09)(-.09,1.91)
  \psline(0.09,1.91)(.91,1.09)\pscircle(-1,1){.09}
  \pscircle(1,1){.09}\psline(0,1.09)(0,1.91)
  \pscircle(0,1){.09}\psline(0,0.09)(0,0.91)
  \psline(-.91,.91)(-.09,.09)\psline(.09,.09)(.91,.91)\pscircle(0,0){.09}
  \rput( 0  ,-.4){1,2,3}
  \rput(-1.5,1  ){12,3}
  \rput(-0.45,1  ){13,2}
  \rput( 1.5,1  ){23,1}
  \rput( 0  ,2.6){123}}\rput(0,-1){$\Pi_3$}\endpspicture}}
	\[ \ell(\pi) = n - |\pi|\]


\newpage

%\definition
%Let $L$ be a lattice and $G$ be an abelian group.\\
%A function $v: L \to G$ is a \emph{valuation} if, for all $x,y \in L$,
%	\[ v(x) + v(y) = v(x \vee y) + v(x \wedge y)\,.\]
%
%
%\begin{thm}{The Inclusion-Exclusion Principle (lattices)}
%	\[ v \lr{\bigvee_{x \in L} x} = \sum_{J \subseteq L} (-1)^{|J|+1} v \lr{\bigwedge_{y
%\in J} y}\]
%\end{thm}
%
%
%\begin{proof}
%Consider an element $z \in L$ and use induction on $|L|$:
%{\bf\huge Does $L$ have to be distributive or something here?
%It's not correct: the alternating sign stuff is for Boolean lattices. See Narushima's papers.}
%\begin{align*}
%	  v \lr{\bigvee_{x \in L} x}
%    = v \lr{z \vee \bigvee_{x \in L - \{z\}} x }
%  & = v(z) + v\lr{\bigvee_{x \in L - \{z\}} x} - v\lr{\bigvee_{x \in L - \{z\}} x \wedge
%  z}\\
%  & = v(z) + \sum_{J \subseteq L - \{z\}} (-1)^{|J|+1} v \lr{\bigwedge_{y \in J} y}
%      - \sum_{J \subseteq L - \{z\}} (-1)^{|J|+1} v\lr{\bigwedge_{y \in J} y \wedge z}\\
%  & = \sum_{J \subseteq L} (-1)^{|J|+1} v \lr{\bigwedge_{x \in J} x}\,. \qedhere
%\end{align*}
%\end{proof}


\definition
Let $P$ be a finite poset.
The \emph{zeta function} of $P$ is the matrix $\zeta$ with entries
	\[ \zeta(x,y) = \begin{cases}
		1 & x \leq y\\
		0 & \text{otherwise}.
	\end{cases}\]
The \emph{M\"obius function} of $P$ is the inverse $\mu := \zeta^{-1}$.
By antisymmetry, the row- and column indices of $\zeta$ may be ordered so it is
upper-triangular.
In that case, $\mu$ is also upper-triangular.


\begin{thm}{Theorem}
Let $c_k (x,y)$ denote the number of chains in $P$ of size $k$ from $x$ to $y$.
Then
  \[ \mu (x,y) = \sum_{k \geq 1} (-1)^{k-1} c_k (x,y)\,.\]
\end{thm}
The proof is left as an {\bfseries exercise}!


\example
For the previous example with the lattice $[n]$ under the usual order $\leq$,
	\[
        \zeta
      = \begin{pmatrix}
          1 & 1 & 1 & 1 \\
          0 & 1 & 1 & 1 \\
          0 & 0 & 1 & 1 \\
          0 & 0 & 0 & 1
	    \end{pmatrix}\quad\text{and}\quad
     \mu = \begin{pmatrix}
		1 & -1 & 0 & 0 \\ 0 & 1 & -1 & 0 \\ 0 & 0 & 1 & -1\\ 0 & 0 & 0 & 1
	\end{pmatrix}\,.\quad\text{In general},\quad
	  \mu (x,y) = \begin{cases}
		1 & x=y \\
       -1 & x=y-1\\
        0 & \text{otherwise.}
	  \end{cases}
    \]

%\newpage
\example
For the previous example with the Boolean lattice $\mathcal{B}_n$ under inclusion
$\subseteq$,
	\[ \mu(A,B) = \begin{cases}
		(-1)^{\ell(B) - \ell(A)} = (-1)^{|B-A|} & A\subseteq B\\
		0                                       & \text{otherwise.}	
	\end{cases}\]
To prove this, we have that for $A \subseteq B$,
\begin{align*}
	(\zeta \mu)_{AB} & = \sum_{C} \zeta(A,C) \mu(C,B)\hspace*{-2mm}
	& = \sum_{A \subseteq C \subseteq B} \hspace*{-2mm} (-1)^{|B-C|}
	  = (-1)^{|B|}\hspace*{-2mm} \sum_{A \subseteq C \subseteq B} \hspace*{-2mm}
(-1)^{|C|}
	  = \begin{cases}
          ((-1)^{|B|})^2 & A = B\\
          0              & \text{otherwise.}	
        \end{cases}
\end{align*}
Hence, $\zeta\mu = I$.
Similarly, $\mu\zeta = I$, so $\mu = \zeta^{-1}$.
\hfill$\Box$


\example
For the previous example with the lattice of divisors of $n$ under division $|$,
\begin{align*}
  \mu(a,b)&  = \begin{cases}
  (-1)^{\ell(b) - \ell(a)} = (-1)^{\ell(b/a)} & a|b\\
  0 & \text{otherwise.}
\end{cases}\\
& = \mu\lr{\frac{b}{a}}\,.
\end{align*}


\newpage
\example
For the previous example with the subspaces of $\FF_2^2$,
	\[
      \zeta = \begin{pmatrix}
		1&1&1&1&1\\0&1&0&0&1\\0&0&1&0&1\\0&0&0&1&1\\0&0&0&0&1
	\end{pmatrix}\qquad\text{and}\qquad
      \mu = \begin{pmatrix}
		1&-1&-1&-1&2\\0&1&0&0&-1\\0&0&1&0&-1\\0&0&0&1&-1\\0&0&0&0&1
	\end{pmatrix}\,.\]
In general, if the vector space is over $\FF_q$, then
	\[ \mu(U,V) = \begin{cases}
		(-1)^k q^{\binom{k}{2}} & U \subseteq V\\
		0  & \text{otherwise}
	\end{cases}\]
where $k = \ell(V) - \ell(U) = \dim(V) - \dim(U)$.


\begin{thm}{M\"obius Inversion}
\begin{align*}
	g = \zeta f & \iff f = \mu g\\
	h = f\zeta  & \iff f = h\mu\,.
\end{align*}
Equivalently,
\begin{align*}
	g(x) = \sum_{a : a \leq x} f(a) \text{ for all } x \in P & \iff f(x)
         = \sum_{a : a \leq x} \mu (a,x) g(a) \text{ for all } x \in P\\
	h(x) = \sum_{b : b \geq x} f(b) \text{ for all } x \in P & \iff f(x)
         = \sum_{b : b \geq x} \mu (x,b) h(b) \text{ for all } x \in P\,.
\end{align*}
\end{thm}


%\newpage
M\"obius Inversion is a strong generalisation of the Inclusion-Exclusion Principle.\\
As the following proof shows, the latter is a special case of the former.


\medskip
\noindent
{\bfseries Inclusion-Exclusion Principle, Proof III.}\\
Let $P := \Pf(I) \equiv \Bf_{|I|}$ and for each $\emptyset\neq J \in P$, define
\begin{align*}
	f(J) & := |\{a : a \in A_j \text{ if and only if } j \in J\}|\\
	g(J) & := |\{a : a \in A_j \text{ for all } j \in J\}| = \abs{\bigcap_{j \in J}
A_j}\,,
\end{align*}
and $f(\emptyset) := 0$ and $g(\emptyset) := \bigl|\bigcup_{i \in I} A_i\bigr|$.\\
Then $\ds g(J) = \sum_{K\supseteq J} f(K)$ for all $J \in P$.
By M\"obius Inversion,
	\[ f(J) = \sum_{K \supseteq J} \mu(J,K) g(K) = \sum_{K \supseteq J} (-1)^{|K-J|}
g(K)\,.\]
Hence,
\begin{align*}
        \abs{\bigcup_{i \in I} A_i}
    = g(\emptyset)
 & = \sum_{K \subseteq I} (-1)^{|K|} g(K) - \sum_{\emptyset \neq K \subseteq I} (-1)^{|K|}
 g(K)\\
 & = f(\emptyset) - \sum_{\emptyset \neq K \subseteq I} (-1)^{|K|} g(K)
   = 0 - \sum_{\emptyset \neq K \subseteq I} (-1)^{|K|} \abs{\bigcap_{j \in K} A_j}
   = \sum_{\emptyset \neq J \subseteq I} (-1)^{|J|+1} \abs{\bigcap_{j \in J} A_j}\,.\qed
\end{align*}

\newpage
\section*{P\'olya Counting}


P\'olya counting allows us to approach problems such as
counting the number of configurations of a Rubik's cube and the number of different ways to tile a surface with some given tiles.
These questions assume certain symmetries that we ignore and just count equivalence classes.

\example
We want to count the number of bracelets that can be made with six beads
that are each either black or white.
If you are wearing the bracelet, then rotating it doesn't change it.
If you take it off however, then it is seen to be the same bracelet if you either rotate or turn it around (i.e., reflect it).

We can of course just count by brute force:

\newcommand{\whitebead}{\pspicture(-.175,-.175)(.2,.2)\pscircle[linecolor=darkgray,linewidth=.5pt,fillstyle=solid,shadow=false,fillcolor=white](0,0){.16}\endpspicture}
\newcommand{\blackbead}{\pspicture(-.175,-.175)(.2,.2)\pscircle[linecolor=darkgray,linewidth=.5pt,fillstyle=solid,shadow=false,fillcolor=gray   ](0,0){.16}\endpspicture}
\newcommand{\graybead}{\pspicture(-.175,-.175)(.2,.2)\pscircle[linecolor=darkgray,linewidth=.5pt,fillstyle=solid,shadow=false,fillcolor=halfgray](0,0){.16}\endpspicture}
\newcommand{\redbead}{\pspicture(-.175,-.175)(.2,.2)\pscircle[linecolor=darkred,linewidth=.5pt,fillstyle=solid,shadow=false,fillcolor=red](0,0){.16}\endpspicture}
\newcommand{\bluebead}{\pspicture(-.175,-.175)(.2,.2)\pscircle[linecolor=darkblue,linewidth=.5pt,fillstyle=solid,shadow=false,fillcolor=blue](0,0){.16}\endpspicture}
\newcommand{\greenbead}{\pspicture(-.175,-.175)(.2,.2)\pscircle[linecolor=darkgreen,linewidth=.5pt,fillstyle=solid,shadow=false,fillcolor=green](0,0){.16}\endpspicture}

\newcommand{\bt}[6]{\begin{pspicture}(-.478,-.303)(.478,.303)\psset{linecolor=darkgray,fillstyle=solid,shadow=false,fillcolor=white}
  {#1\pscircle(  .35 ,0    ){.175}}
  {#2\pscircle( 0.175,0.303){.175}}
  {#3\pscircle(-0.175,0.303){.175}}
  {#4\pscircle(-0.35 ,0    ){.175}}
  {#5\pscircle(-0.175,-.303){.175}}
  {#6\pscircle( 0.175,-.303){.175}}\end{pspicture}}

\newcommand{\bw}{\psset{fillcolor=offwhite}}
\newcommand{\bb}{\psset{fillcolor=gray}}

\newcommand{\pcexcc}[3]{\begin{center}#3\pspicture[linewidth=.5pt](0,0)(12,11.3)#2%
  \rput(0,10.5){\bt{}{}{}{}{}{}}   \rput(1.5 ,10.5){\bt{\bb}{}{}{}{}{}}\rput(3,10.5){\bt{}{\bb}{}{}{}{}}\rput(4.5,10.5){\bt{}{}{\bb}{}{}{}}
  \rput(6,10.5){\bt{}{}{}{\bb}{}{}}\rput(7.5,10.5){\bt{}{}{}{}{\bb}{}}\rput(9,10.5){\bt{}{}{}{}{}{\bb}}\rput(10.5,10.5){\bt{\bb}{\bb}{}{}{}{}}
  \rput(0, 9  ){\bt{}{\bb}{\bb}{}{}{}}\rput(1.5,9){\bt{}{}{\bb}{\bb}{}{}}\rput(3,9){\bt{}{}{}{\bb}{\bb}{}}\rput(4.5,9){\bt{}{}{}{}{\bb}{\bb}}
  \rput(6, 9  ){\bt{\bb}{}{}{}{}{\bb}}\rput(7.5,9){\bt{\bb}{}{\bb}{}{}{}}\rput(9,9){\bt{}{\bb}{}{\bb}{}{}}\rput(10.5,9){\bt{}{}{\bb}{}{\bb}{}}
  \rput(0, 7.5){\bt{}{}{}{\bb}{}{\bb}}\rput(1.5,7.5){\bt{\bb}{}{}{}{\bb}{}}\rput(3,7.5){\bt{}{\bb}{}{}{}{\bb}{}}\rput(4.5,7.5){\bt{\bb}{}{}{\bb}{}{}}
  \rput(6, 7.5){\bt{}{\bb}{}{}{\bb}{}}\rput(7.5,7.5){\bt{}{}{\bb}{}{}{\bb}}\rput(9,7.5){\bt{\bb}{\bb}{\bb}{}{}{}}\rput(10.5,7.5){\bt{}{\bb}{\bb}{\bb}{}{}}
  \rput(0, 6  ){\bt{}{}{\bb}{\bb}{\bb}{}}\rput(1.5,6){\bt{}{}{}{\bb}{\bb}{\bb}}\rput(3,6){\bt{\bb}{}{}{}{\bb}{\bb}}\rput(4.5,6){\bt{\bb}{\bb}{}{}{}{\bb}}
  \rput(6, 6  ){\bt{\bb}{\bb}{}{\bb}{}{}}\rput(7.5,6){\bt{}{\bb}{\bb}{}{\bb}{}}\rput(9,6){\bt{}{}{\bb}{\bb}{}{\bb}}\rput(10.5,6){\bt{\bb}{}{}{\bb}{\bb}{}}
  \rput(0, 4.5){\bt{}{\bb}{}{}{\bb}{\bb}}\rput(1.5,4.5){\bt{\bb}{}{}{\bb}{}{\bb}}\rput(3,4.5){\bt{\bb}{\bb}{}{}{\bb}{}}\rput(4.5,4.5){\bt{}{\bb}{\bb}{}{}{\bb}}
  \rput(6, 4.5){\bt{\bb}{}{\bb}{\bb}{}{}}\rput(7.5,4.5){\bt{}{\bb}{}{\bb}{\bb}{}}\rput(9,4.5){\bt{}{}{\bb}{}{\bb}{\bb}}\rput(10.5,4.5){\bt{\bb}{}{}{\bb}{}{\bb}}
  \rput(0, 3  ){\bt{\bb}{}{\bb}{}{\bb}{}}\rput(1.5,3){\bt{}{\bb}{}{\bb}{}{\bb}{}}\rput(3,3){\bt{\bb}{\bb}{\bb}{\bb}{}{}}\rput(4.5,3){\bt{}{\bb}{\bb}{\bb}{\bb}{}}
  \rput(6, 3  ){\bt{}{}{\bb}{\bb}{\bb}{\bb}}\rput(7.5,3){\bt{\bb}{}{}{\bb}{\bb}{\bb}}\rput(9,3){\bt{\bb}{\bb}{}{}{\bb}{\bb}}\rput(10.5,3){\bt{\bb}{\bb}{\bb}{}{}{\bb}}
  \rput(0, 1.5){\bt{\bb}{\bb}{\bb}{}{\bb}{}}\rput(1.5,1.5){\bt{}{\bb}{\bb}{\bb}{}{\bb}}\rput(3,1.5){\bt{\bb}{}{\bb}{\bb}{\bb}{}}\rput(4.5,1.5){\bt{}{\bb}{}{\bb}{\bb}{\bb}}
  \rput(6, 1.5){\bt{\bb}{}{\bb}{}{\bb}{\bb}{\bb}}\rput(7.5,1.5){\bt{\bb}{\bb}{}{\bb}{}{\bb}}\rput(9,1.5){\bt{\bb}{\bb}{}{\bb}{\bb}{}}\rput(10.5,1.5){\bt{}{\bb}{\bb}{}{\bb}{\bb}}
  \rput(0, 0  ){\bt{\bb}{}{\bb}{\bb}{}{\bb}}\rput(1.5,0){\bt{\bb}{\bb}{\bb}{\bb}{\bb}{}}\rput(3,0){\bt{}{\bb}{\bb}{\bb}{\bb}{\bb}}\rput(4.5,0){\bt{\bb}{}{\bb}{\bb}{\bb}{\bb}}
  \rput(6, 0  ){\bt{\bb}{\bb}{}{\bb}{\bb}{\bb}}\rput(7.5,0){\bt{\bb}{\bb}{\bb}{}{\bb}{\bb}}\rput(9,0){\bt{\bb}{\bb}{\bb}{\bb}{}{\bb}}\rput(10.5,0){\bt{\bb}{\bb}{\bb}{\bb}{\bb}{\bb}}
  \psset{linecolor=white,fillcolor=white,opacity=0.75,fillstyle=solid,shadow=false}#1\endpspicture\end{center}}

\newcommand{\pcexccav}{
  \psframe(2.4,9.9)( 9.6,11.1)
  \psframe(-.6,8.4)( 6.6, 9.6)
  \psframe(8.4,8.4)(11.1, 9.6)
  \psframe(-.6,6.9)( 3.6, 8.1)
  \psframe(5.4,6.9)( 8.1, 8.1)
  \psframe(9.9,6.9)(11.1, 8.1)
  \psframe(-.6,5.4)( 5.1, 6.6)
  \psframe(6.9,5.4)(11.1, 6.6)
  \psframe(-.6,3.9)( 2.1, 5.1)
  \psframe(3.9,3.9)(11.1, 5.1)
  \psframe( .9,2.4)( 2.1, 3.6)
  \psframe(3.9,2.4)(11.1, 3.6)
  \psframe( .9, .9)( 8.1, 2.4)
  \psframe(9.9, .9)(11.1, 2.4)
  \psframe(-.6,-.6)(  .6,  .6)
  \psframe(2.4,-.6)( 9.6,  .6)}

\newcommand{\mybracelet}[1]{{\psset{unit=4mm,fillstyle=solid,linewidth=.05,linecolor=darkgray,linearc=.05,shadow=false}#1}}

\mybracelet{\pcexcc{\pcexccav}{}{}}

Of the $2^6 = 64$ strictly different bracelets, 14 are distinct up to rotation.
If we ignore reflections, then the two bracelets
\mybracelet{\bt{\bb}{\bb}{}{\bb}{}{}}
and
\mybracelet{\bt{\bb}{\bb}{}{}{\bb}{}}
are seen as identical, and so we have only 13 distinct bracelets.

This brute force approach is not feasible in general,
and we will now show to count objects under symmetries in more systematics fashion.

\begin{thm}{Burnside's Lemma (Cauchy 1845, Frobenius 1887)}
The number of orbits of a permutation group $G$ acting on a set $X$ if
	\[ \frac{1}{|G|} \sum_{ g \in G} \phi (g)\]
where $\phi(g) : = |\{x \in X : g(x)=x\}|$ is the number of fixed points of $g$.
\end{thm}

\begin{proof}
For each $x \in X$, let $O_x = \{g(x) : g \in G\}$
and $S_x = \{g \in G : g(x) = x\}$ be the orbit and stabilise of $x$ in $G$.
Let $\mathcal{O}$ be the set of orbits of $G$.
By the Orbit-Stabiliser Theorem, $|G| = |S_x||O_x|$, and hence,
\begin{align*}
      |\mathcal{O}|
    = \sum_{O \in \mathcal{O}} 1
    = \sum_{O \in \mathcal{O}} \frac{|O|}{|O|}
    = \sum_{O \in \mathcal{O}} \sum_{x \in O} \frac{1}{|O|}
  &	= \sum_{x \in X} \sum_{\substack{O \in \mathcal{O}:\\O = O_x}} \frac{1}{|O|}
    = \sum_{x \in X} \frac{1}{|O_x|}
    = \frac{1}{|G|} \sum_{x \in X} |S_x|\\
  & = \frac{1}{|G|} \sum_{x \in X} \sum_{\substack{g \in G:\\ g(x) = x}} 1
    = \frac{1}{|G|} \sum_{g \in G} \sum_{\substack{x \in X:\\ g(x) = x}} 1
    = \frac{1}{|G|} \sum_{g \in G} \phi(g)\,.\qedhere
\end{align*}
\end{proof}

\example
We can use Burnside's Lemma to count the bracelet from the example above.
Here, $G = D_6$, the dihedral group of rotations and reflections on a hexagon.
The orbits of $G$ are the bracelet equivalence classes that we wish to count.
The group $G$ is generated by a $60^{\circ}$ rotation $r$ and a reflection $s$.

Each bracelet $x \in X$ is a fixed point of the identity $e \in G$, so $\phi(e) = 64$.
For $g :=r,r^{-1}$, the fixed points of $g$ are the bracelets
\mybracelet{\bt{}{}{}{}{}{}}
and
\mybracelet{\bt{\bb}{\bb}{\bb}{\bb}{\bb}{\bb}}, so $\phi(g) = 2$.

We can continue to find all of the values of $\phi(g)$.
They are
	\[ 64,2,2,4,4,8,16,8,16,8,16,8\,.\]
	
By Burnside's Lemma, the number of orbits, and thus bracelets, is
	\[ \frac{1}{|G|} \sum_{g \in G} \phi(g) =
  \frac{1}{12} (64+2+2+4+4+8+16+8+16+8+16+8) = \frac{156}{12} = 13\,.\]
	
\example
Consider bead strings of length two, in three colours.
The group $G$ is here just $\{e,s\}$ where $e$~is the identity element and where $s$ swaps the beads.
Then $\phi(e) = 9$ and $\phi (s) = 3$.

By Burnside's Lemma, the number of these bead strings is
	\[ \frac{1}{|G|} \sum_{g \in G} \phi(g) = \frac{1}{2} (3+9) = 6\,.\]
	
\example
Now consider bead strings of length three, in black and white.\\
The group is $G$ is again just $\{e,s\}$. Then $\phi(e) = 8$, and $\phi (s) = 4$.

By Burnside's Lemma, the number of these bead strings is
	\[ \frac{1}{|G|} \sum_{g \in G} \phi(g) = \frac{1}{2} (8+4) = 6\,.\]
Let $A$ be a set and $B$ be a set of colours, both finite.\\
Let $G$ be a group of permutations acting on $A$.\\
Further, let $G$ act on $B^A$, the $B$-colourings of $A$, by
	\[ \sigma(f) := f(\sigma^{-1}(x))\,.\]

\example
Consider again the bracelet problem. Here, we could let
\begin{myitemize}
	\item[\mybullet] $A$ be the set of uncoloured beads in the bracelet.
	\item[\mybullet] $B$ be the set of colours
	\item[\mybullet] $B^A$ be the bracelet colourings, i.e. the coloured bracelets.
	\item[\mybullet] $G$ be the dihedral group acting on $A$.
\end{myitemize}
As before, the orbits of $G$ count the different bracelets.

\newpage
\definition
Let $\pi$ be a permutation.\\
The \emph{cycle decomposition} of $\pi$ is
the unique product of cycles $\pi = \sigma_1 \dots \sigma_n$.\\
The \emph{type} of $\pi$ is the formal product $1^{z_1} 2^{z_2} \dots$,
with $z_i = |\{j: |\sigma_j| = i\}|$.

\example
The permutation
	\[ \pi = \binom{12345678}{34516287}\]
has cycle decomposition
	\[ \pi = \binom{78}{87}\binom{134}{341} \binom{256}{562}\]
and thus has type $2^1 3^2$.

\definition
The \emph{cycle index} of a group $G$ is the polynomial
	\[ Z_G (X_1, \dots, X_n) := \frac{1}{|G|} \sum_{\sigma \in G} X_1^{z_1 (\sigma)} \dots X_n^{z_n (\sigma)}\,.\]

\example
Let $G$ be the cyclic group $C_n$.
For each divisor $d | n$, there are $\phi(d)$ permutations of order~$d$,
and each of these has $\frac{n}{d}$ cycles of length~$d$.
Thus, the cycle index of $C_n$ is
	\[ Z_G (X_1, \dots, X_n) = \frac{1}{n} \sum_{d |n} \phi (d) X_d^{n/d}\,.\]
	
\begin{thm}{Theorem}
Let $c_k (G)$ be the number of permutations with exactly $k$ cycles.
The number of orbits on $B^A$ is
		\[ \frac{1}{|G|} \sum_{k=1}^\infty c_k (G) |B|^k\,.\]
\end{thm}

\begin{proof}
A fixed point of $\sigma \in G$ is a colouring $f \in B^A$ for which $\sigma(f) = f$.\\
That is, $f(a) = f(\sigma^{-1}(a))$ for all $a \in A$.
Hence, $f$ is constant on each cycle $\sigma_i$ of $\sigma$.

Conversely, if $f$ is constant on each cycle $\sigma_i$,
then $f$ is a fixed point for $\sigma$.
Hence, if $\sigma$ has $k$ cycles,
then the number of fixed points for $\sigma$ is $|B|^k$.
By Burnside's Lemma, the number of orbits is thus
\begin{align*}
	    \frac{1}{|G|} \sum_{\sigma \in G} \phi(x)
    & = \frac{1}{|G|} \sum_{k=1}^\infty \sum_{\substack{\sigma \in G:\\ \sigma \text{ has } k \text{ cycles}}} \hspace*{-3mm}\phi(\sigma)
	  = \frac{1}{|G|} \sum_{k=1}^\infty \sum_{\substack{\sigma \in G:\\ \sigma \text{ has } k \text{ cycles}}} \hspace*{-3mm}|B|^k
	  = \frac{1}{|G|} \sum_{k=1}^\infty c_k (G) |B|^k\,.\qedhere
\end{align*}
\end{proof}

The above theorem may be re-expressed in the following way.

\begin{thm}{P\'olya's Theorem (simple)}
	The number of orbits of $G$ on $B^A$ is
		\[ Z_G (|B|, \dots, |B|) = \frac{1}{|G|} \sum_{\sigma \in G} |B|^{z_1 (\sigma) + \dots + z_n (\sigma)}\,.\]
\end{thm}
This result can be generalised significantly.


\example
Consider bracelets with $n$ beads in $b$ colours
identical under rotational symmetry but distinct under reflections.
Then $G$ is the cyclic group $C_n$ and $|B|= b$.\\
By P\'olya's Theorem, the number of distinct bracelets with $n$ beads is
\[
  Z_G(b,\ldots,b) = \frac{1}{n} \sum_{d|n} \varphi(d) b^{n/d}\,.
\]
For $n= 6$,
  \[
      Z_G(b,\ldots,b)
    = \frac{1}{6} \bigl(\varphi(1) b^{6/1}+\varphi(2) b^{6/2}+\varphi(3) b^{6/3}+\varphi(6) b^{6/6}\bigr)
    = \frac{1}{6} \bigl(b^6 + b^3 + 2 b^{2} + 2b\bigr)\,.
  \]
For instance, the number of bracelets with $6$ beads in $b = 3$ colours is
  \[
    \frac{1}{6} \bigl(3^6 + 3^3 + 2\cdot3^{2} + 2\cdot3\bigr)
    = 130\,.\]
As we have seen, the number of bracelets with $6$ beads in $b = 2$ colours~is\vspace*{-2mm}
  \[\frac{1}{6} \bigl(2^6 + 2^3 + 2\cdot2^{2} + 2\cdot2\bigr)
    = 14\black\,.\]



\newpage
\section*{Generating Functions}

To appear.


\newpage
\begin{thebibliography}{9}

\bibitem{aigner79} M.~Aigner,
{\sl Combinatorial Theory}, Springer-Verlag, New York, 1979.

%\bibitem{AiZi10}
%M.~Aigner and G.M.~Ziegler,
%{\sl Proofs from The Book}, 4th edition, Springer-Verlag, Berlin, 2010.

%\bibitem{anderson87} I.~Anderson,
%{\sl Combinatorics of Finite Sets}, Oxford University Press, New York, 1987.

%\bibitem{bogomolny}
%A.~Bogomolny, {\sl Pigeonhole Principle}, \url{http://www.cut-the-knot.org/do_you_know/pigeon.shtml}, 2016--03.

%\item{bollobas86} B.~Bollob\'as,
%{\sl Combinatorics. Set Systems, Hypergraphs, Families of Vectors and Combinatorial Probability},
%Cambridge University Press, Cambridge, 1986.

%\bibitem{BoMu76} J.A.~Bondy and U.S.R.~Murty,
%{\sl Graph Theory with Applications}, Macmillan Press, New York, 1976.

%\bibitem{brandt01}
%J.~Brandt, {\sl Kombinatorik}, Aarhus University, lecture notes, 2001.

%\bibitem{britz07a} T.~Britz,
%Higher support matroids,
%{\sl Discrete Math.}~{\bf 307} (2007), 2300--2308.

%\bibitem{BrJoMaSh12} T.~Britz, T.~Johnsen, D.~Mayhew, and K.~Shiromoto,
%Wei-type duality theorems for matroids,
%{\sl Des.\ Codes Cryptogr.}~{\bf 62} (2012), 331--341.

%\bibitem{FoFu62} L.R.~Ford, Jr.\ and D.R.~Fulkerson,
%{\sl Flows in Networks}, Princeton Univ.\ Press, 1962.

\bibitem{GrGrLo95} R.L.~Graham, M.~Gr\"otschel, and L.~Lov\'asz (eds.),
{\sl Handbook of Combinatorics. I--II}, North-Holland, Amsterdam, 1995.

%\bibitem{GrRoSp90}
%R.L.~Graham, B.L.~Rothschild, and J.~Spencer,
%{\sl Ramsey Theory}, 2nd edition, John Wiley \&\ Sons, Inc., New York, 1990.

%\bibitem{jukna11} S.~Jukna,
%{\sl Extremal Combinatorics. With Applications in Computer Science}, 2nd ed., Springer, Heidelberg, 2011.

%\bibitem{LaRob14}
%B.M.~Landman and A.~Robertson,
%{\sl Ramsey Theory on the Integers}, 2nd edition, AMS, Providence, RI, 2014.

%\bibitem{LoPl86} L.~Lov\'asz and M.D.~Plummer,
%{\sl Matching Theory}, Akad\'emiai Kiad\'o, North Holland, Budapest, 1986.

\bibitem{vLiWi92} J.H.~van Lint and R.M.~Wilson,
{\sl A Course in Combinatorics}, Cambridge University Press, 1992.

\bibitem{liu68} C.L.~Liu,
{\sl Introduction to Combinatorial Mathematics}, McGraw-Hill Book Co., New York,~1968.

%\bibitem{rado42} R.~Rado,
%A theorem on independence relations,
%{\sl Quart.\ J.~Math., Oxford Ser.}~{\bf 13} (1942), 83--89.

\bibitem{stanley97} R.P.~Stanley,
{\sl Enumerative Combinatorics. Vol.~1}, Cambridge University Press, 1997.

%\bibitem{wei91} V.K.~Wei,
%Generalized Hamming weights for linear codes,
%{\sl IEEE Trans.\ Inform.\ Theory}~{\bf 37} (1991), 1412--1418.

\end{thebibliography}


\end{document}
